#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import logging
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import shutil
from datetime import datetime
from deep_translator import GoogleTranslator
import requests
import time
import re
import sys
import subprocess
from dotenv import load_dotenv
from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer
import struct
import mimetypes
from collections import defaultdict, Counter

# Chargement des variables d'environnement
load_dotenv()

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('translation.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class SpecialTokens:
    """Gestion des tokens sp√©ciaux pour Persona 3 FES."""
    
    # Tokens de formatage du jeu (codes de contr√¥le)
    GAME_FORMAT_TOKENS = {
        # Codes de formatage de texte
        r'\{F[0-9A-F]{2}\s+[0-9A-F]{2}\s+[0-9A-F]{2}\s+[0-9A-F]{2}\}': 'GAME_FORMAT_1',  # {F2 08 FF FF}
        r'\{F[0-9A-F]{2}\s+[0-9A-F]{2}\}': 'GAME_FORMAT_2',  # {F1 3F}
        r'\{[0-9A-F]{2}\}': 'GAME_FORMAT_3',  # {0A}
        r'\{00\}': 'GAME_END',  # Fin de message
        
        # Codes de dialogue et d'interface
        r'\{NAME\d+\}': 'PLAYER_NAME',  # Nom du joueur
        r'\{ITEM\d+\}': 'ITEM_NAME',  # Nom d'objet
        r'\{PERSONA\d+\}': 'PERSONA_NAME',  # Nom de Persona
        r'\{SKILL\d+\}': 'SKILL_NAME',  # Nom de comp√©tence
        r'\{LOCATION\d+\}': 'LOCATION_NAME',  # Nom de lieu
        
        # Codes de formatage avanc√©s
        r'\{COLOR\d+\}': 'TEXT_COLOR',  # Couleur du texte
        r'\{SPEED\d+\}': 'TEXT_SPEED',  # Vitesse d'affichage
        r'\{WAIT\d+\}': 'TEXT_WAIT',  # Pause dans le texte
        r'\{CLEAR\}': 'CLEAR_TEXT',  # Effacer le texte
        r'\{WINDOW\d+\}': 'WINDOW_TYPE',  # Type de fen√™tre
        
        # Codes de son et d'animation
        r'\{SOUND\d+\}': 'SOUND_EFFECT',  # Effet sonore
        r'\{VOICE\d+\}': 'VOICE_LINE',  # Ligne vocale
        r'\{ANIM\d+\}': 'ANIMATION',  # Animation
        r'\{FACE\d+\}': 'FACE_EMOTION',  # Expression faciale
        
        # Codes de menu et de choix
        r'\{CHOICE\d+\}': 'MENU_CHOICE',  # Option de menu
        r'\{YESNO\}': 'YES_NO_PROMPT',  # Prompt Oui/Non
        r'\{INPUT\}': 'TEXT_INPUT',  # Saisie de texte
        r'\{CURSOR\d+\}': 'CURSOR_POS',  # Position du curseur
        
        # Codes de statut et de combat
        r'\{HP\d+\}': 'HP_VALUE',  # Points de vie
        r'\{SP\d+\}': 'SP_VALUE',  # Points de magie
        r'\{STATUS\d+\}': 'STATUS_EFFECT',  # Effet de statut
        r'\{DAMAGE\d+\}': 'DAMAGE_VALUE',  # Valeur de d√©g√¢ts
    }
    
    # Tokens de formatage standard
    FORMAT_TOKENS = {
        '\n': 'NEWLINE',
        '\t': 'TAB',
        '\r': 'CARRIAGE_RETURN',
        '\\n': 'NEWLINE_ESC',
        '\\t': 'TAB_ESC',
        '\\r': 'CARRIAGE_RETURN_ESC',
        '„Äå': 'DIALOG_START',  # Guillemets japonais pour dialogue
        '„Äç': 'DIALOG_END',
        '„Äé': 'THOUGHT_START',  # Guillemets japonais pour pens√©es
        '„Äè': 'THOUGHT_END'
    }
    
    # Tokens de commande
    COMMAND_TOKENS = {
        'MSG_': 'MESSAGE_ID',
        'CMD_': 'COMMAND_ID',
        'EVT_': 'EVENT_ID',
        'SCENE_': 'SCENE_ID',
        'BATTLE_': 'BATTLE_ID',
        'QUEST_': 'QUEST_ID'
    }
    
    @staticmethod
    def extract_game_tokens(text: str) -> tuple:
        """
        Extrait les tokens de formatage du jeu et le texte √† traduire.
        Retourne un tuple (tokens, texte_clean).
        """
        tokens = []
        clean_text = text
        
        # Extraction des tokens de formatage du jeu
        for pattern, token_type in SpecialTokens.GAME_FORMAT_TOKENS.items():
            matches = re.finditer(pattern, text)
            for match in matches:
                token = match.group(0)
                # Stocke le token avec sa position et son type
                tokens.append({
                    'token': token,
                    'type': token_type,
                    'position': match.start(),
                    'length': len(token)
                })
                # Remplace le token par un espace pour pr√©server la longueur
                clean_text = clean_text[:match.start()] + ' ' * len(token) + clean_text[match.end():]
        
        # Nettoyage des espaces multiples tout en pr√©servant la structure
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        
        return tokens, clean_text
    
    @staticmethod
    def reconstruct_text(clean_text: str, tokens: list) -> str:
        """
        Reconstruit le texte original avec les tokens de formatage.
        Pr√©serve la structure et le formatage original.
        """
        # Trie les tokens par position d√©croissante pour ne pas perturber les indices
        sorted_tokens = sorted(tokens, key=lambda x: x['position'], reverse=True)
        
        result = clean_text
        for token_info in sorted_tokens:
            # Ins√®re le token √† sa position originale
            pos = token_info['position']
            result = result[:pos] + token_info['token'] + result[pos:]
        
        return result
    
    @staticmethod
    def is_special_token(text: str) -> bool:
        """V√©rifie si le texte contient des tokens sp√©ciaux."""
        # V√©rifie les tokens de formatage du jeu
        if any(re.search(pattern, text) for pattern in SpecialTokens.GAME_FORMAT_TOKENS.keys()):
            return True
            
        # V√©rifie les tokens de formatage standard
        if any(token in text for token in SpecialTokens.FORMAT_TOKENS):
            return True
            
        # V√©rifie les tokens de commande
        if any(text.startswith(token) for token in SpecialTokens.COMMAND_TOKENS):
            return True
            
        return False
    
    @staticmethod
    def preserve_special_tokens(original_text: str, translated_text: str) -> str:
        """Pr√©serve les tokens sp√©ciaux dans le texte traduit."""
        # Extraction des tokens du texte original
        tokens, clean_original = SpecialTokens.extract_game_tokens(original_text)
        
        # Si le texte original ne contient que des tokens sp√©ciaux
        if not clean_original.strip():
            return original_text
            
        # Nettoyage du texte traduit
        clean_translated = translated_text.strip()
        
        # Reconstruction du texte avec les tokens originaux
        return SpecialTokens.reconstruct_text(clean_translated, tokens)

class FileAnalyzer:
    """Analyseur automatique de fichiers pour d√©tecter le contenu traduisible."""
    
    def __init__(self):
        self.magic_signatures = {
            # Signatures de fichiers de jeu courants
            b'PM1\x00': 'pm1_format',
            b'PAC\x00': 'pac_format', 
            b'PAK\x00': 'pak_format',
            b'BF\x00\x00': 'bf_format',
            b'TBL\x00': 'tbl_format',
            
            # Signatures g√©n√©riques
            b'RIFF': 'riff_format',
            b'\x89PNG': 'png_image',
            b'MZ': 'executable',
            b'\x7fELF': 'elf_executable',
            
            # Archives
            b'PK\x03\x04': 'zip_archive',
            b'Rar!': 'rar_archive',
            
            # Formats de texte
            b'\xff\xfe': 'utf16_le_text',
            b'\xfe\xff': 'utf16_be_text',
            b'\xef\xbb\xbf': 'utf8_bom_text',
        }
        
        self.text_indicators = [
            # Mots courants en anglais dans les jeux
            br'[Ss]tart',
            br'[Pp]ress',
            br'[Gg]ame\s+[Oo]ver',
            br'[Ll]oading',
            br'[Cc]ontinue',
            br'[Nn]ew\s+[Gg]ame',
            br'[Ss]ave',
            br'[Ll]oad',
            br'[Qq]uit',
            br'[Ee]xit',
            br'[Oo]ptions',
            br'[Ss]ettings',
            br'[Vv]olume',
            br'[Hh]elp',
            br'[Yy]es',
            br'[Nn]o',
            br'[Oo][Kk]',
            br'[Cc]ancel',
            
            # Textes sp√©cifiques √† Persona
            br'[Pp]ersona',
            br'[Tt]artarus',
            br'SEES',
            br'[Ee]voker',
            br'[Ss]hadow',
            br'[Aa]rcana',
            br'[Cc]ompendium',
            br'[Vv]elvet\s+[Rr]oom',
        ]
        
        self.analysis_results = {}
    
    def detect_translation_status(self, file_path: Path) -> Dict:
        """
        D√©tecte si un fichier a d√©j√† √©t√© traduit et son niveau de traduction.
        Retourne des informations sur le statut de traduction.
        """
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
            
            if len(data) == 0:
                return {'status': 'empty', 'confidence': 0.0, 'indicators': []}
            
            # Convertir en texte pour analyse
            text_content = ""
            for encoding in ['utf-8', 'ascii', 'latin1', 'shift_jis']:
                try:
                    text_content = data.decode(encoding, errors='ignore')
                    break
                except:
                    continue
            
            # Indicateurs de traduction fran√ßaise
            french_indicators = [
                # Mots fran√ßais courants dans les jeux
                r'\b(?:bonjour|salut|bienvenue|merci|oui|non|annuler|continuer|quitter)\b',
                r'\b(?:jeu|partie|joueur|d√©marrer|charger|sauvegarder|options)\b',
                r'\b(?:nouveau|ancien|pr√©c√©dent|suivant|retour|aide|fin)\b',
                r'\b(?:appuyez|pressez|cliquez|s√©lectionnez|choisissez)\b',
                
                # Indicateurs sp√©cifiques aux traductions automatiques
                r'\b(?:chargement|chargeme|nouvea|annu|gibier|voit)\b',  # Textes tronqu√©s typiques
                r'\.\.\.+',  # Points de suspension multiples (troncature)
                
                # Accents et caract√®res fran√ßais
                r'[√†√¢√§√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ø√ß]',
                
                # Expressions fran√ßaises de jeu
                r'(?:fin de partie|game over traduit|partie termin√©e)',
                r'(?:essayer √† nouveau|r√©essayer)',
                r'(?:visitez|v√©rifiez|utilisez)',
            ]
            
            # Indicateurs anglais (pour d√©tecter les non-traduits)
            english_indicators = [
                r'\b(?:start|press|game\s+over|loading|new\s+game|continue|quit|yes|no|ok|cancel)\b',
                r'\b(?:welcome|hello|thanks|help|options|settings|save|load)\b',
                r'\b(?:try\s+again|game\s+over|press\s+any\s+key)\b',
            ]
            
            # Compter les occurrences
            french_count = 0
            english_count = 0
            translation_indicators = []
            
            text_lower = text_content.lower()
            
            for pattern in french_indicators:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                if matches:
                    french_count += len(matches)
                    translation_indicators.extend([f"French: {match}" for match in matches[:3]])  # Limiter les exemples
            
            for pattern in english_indicators:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                if matches:
                    english_count += len(matches)
            
            # Calculer le score de traduction
            total_indicators = french_count + english_count
            if total_indicators == 0:
                translation_ratio = 0.0
                status = 'no_text'
            else:
                translation_ratio = french_count / total_indicators
                if translation_ratio >= 0.7:
                    status = 'fully_translated'
                elif translation_ratio >= 0.3:
                    status = 'partially_translated'
                elif english_count > 0:
                    status = 'not_translated'
                else:
                    status = 'unknown'
            
            return {
                'status': status,
                'confidence': translation_ratio,
                'french_indicators': french_count,
                'english_indicators': english_count,
                'indicators': translation_indicators[:5],  # Top 5 exemples
                'total_indicators': total_indicators
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'confidence': 0.0,
                'indicators': [f"Error: {str(e)}"],
                'error': str(e)
            }
    
    def detect_file_format(self, file_path: Path) -> Tuple[str, float]:
        """
        D√©tecte le format d'un fichier et sa probabilit√© de contenir du texte.
        Retourne (format_detect√©, score_de_confiance)
        """
        try:
            with open(file_path, 'rb') as f:
                header = f.read(512)  # Lire les premiers 512 bytes
                
            if not header:
                return 'empty_file', 0.0
            
            # V√©rification des signatures magiques
            detected_format = 'unknown'
            for signature, format_name in self.magic_signatures.items():
                if header.startswith(signature):
                    detected_format = format_name
                    break
            
            # Score bas√© sur la pr√©sence de texte lisible
            text_score = self._calculate_text_score(header)
            
            # Bonus pour les formats de jeu connus
            format_bonus = 0.0
            if detected_format in ['pm1_format', 'pac_format', 'pak_format', 'bf_format', 'tbl_format']:
                format_bonus = 0.3
            elif 'text' in detected_format:
                format_bonus = 0.5
            
            final_score = min(1.0, text_score + format_bonus)
            
            return detected_format, final_score
            
        except Exception as e:
            logging.debug(f"Erreur d'analyse de {file_path}: {e}")
            return 'error', 0.0
    
    def _calculate_text_score(self, data: bytes) -> float:
        """Calcule un score de probabilit√© de pr√©sence de texte."""
        if len(data) == 0:
            return 0.0
        
        # Compteur de caract√®res imprimables
        printable_count = 0
        for byte in data:
            if 32 <= byte <= 126 or byte in [9, 10, 13]:  # ASCII imprimable + TAB/LF/CR
                printable_count += 1
        
        printable_ratio = printable_count / len(data)
        
        # Recherche de mots indicateurs
        indicator_score = 0.0
        for pattern in self.text_indicators:
            if re.search(pattern, data, re.IGNORECASE):
                indicator_score += 0.1
        
        # Score final
        text_score = (printable_ratio * 0.7) + min(indicator_score, 0.3)
        
        return text_score
    
    def analyze_directory(self, directory: Path, max_files: int = None) -> Dict:
        """
        Analyse tous les fichiers d'un r√©pertoire et retourne un rapport.
        """
        analysis_report = {
            'total_files': 0,
            'analyzed_files': 0,
            'promising_files': [],
            'translated_files': [],
            'untranslated_files': [],
            'partially_translated_files': [],
            'by_format': defaultdict(list),
            'by_score': defaultdict(list),
            'by_translation_status': defaultdict(list),
            'errors': [],
            'recommendations': [],
            'translation_summary': {
                'fully_translated': 0,
                'partially_translated': 0,
                'not_translated': 0,
                'no_text': 0,
                'unknown': 0,
                'error': 0
            },
            'ignored_files': 0
        }
        
        all_files = []
        ignored_count = 0
        
        for root, _, files in os.walk(directory):
            for file in files:
                file_path = Path(root) / file
                if file_path.is_file():
                    # Ignorer les fichiers .backup
                    if file_path.suffix.lower() == '.backup' or '.backup' in file_path.name:
                        ignored_count += 1
                        continue
                    all_files.append(file_path)
        
        analysis_report['total_files'] = len(all_files)
        analysis_report['ignored_files'] = ignored_count
        
        # Limiter si demand√©
        if max_files and len(all_files) > max_files:
            all_files = all_files[:max_files]
            analysis_report['note'] = f"Analyse limit√©e aux {max_files} premiers fichiers"
        
        for file_path in all_files:
            try:
                file_format, score = self.detect_file_format(file_path)
                translation_status = self.detect_translation_status(file_path)
                
                file_info = {
                    'path': str(file_path),
                    'name': file_path.name,
                    'size': file_path.stat().st_size,
                    'format': file_format,
                    'text_score': score,
                    'extension': file_path.suffix.lower(),
                    'translation_status': translation_status['status'],
                    'translation_confidence': translation_status['confidence'],
                    'french_indicators': translation_status.get('french_indicators', 0),
                    'english_indicators': translation_status.get('english_indicators', 0),
                    'translation_examples': translation_status.get('indicators', [])
                }
                
                analysis_report['by_format'][file_format].append(file_info)
                analysis_report['analyzed_files'] += 1
                
                # Classer par statut de traduction
                status = translation_status['status']
                analysis_report['by_translation_status'][status].append(file_info)
                analysis_report['translation_summary'][status] += 1
                
                # Classer par score
                if score >= 0.7:
                    analysis_report['by_score']['high'].append(file_info)
                    # Ne consid√©rer comme prometteur que s'il n'est pas d√©j√† traduit
                    if status not in ['fully_translated']:
                        analysis_report['promising_files'].append(file_info)
                        analysis_report['untranslated_files'].append(file_info)
                    elif status == 'fully_translated':
                        analysis_report['translated_files'].append(file_info)
                elif score >= 0.4:
                    analysis_report['by_score']['medium'].append(file_info)
                    if status not in ['fully_translated']:
                        analysis_report['promising_files'].append(file_info)
                        analysis_report['untranslated_files'].append(file_info)
                    elif status == 'fully_translated':
                        analysis_report['translated_files'].append(file_info)
                elif score >= 0.1:
                    analysis_report['by_score']['low'].append(file_info)
                else:
                    analysis_report['by_score']['none'].append(file_info)
                
                # Fichiers partiellement traduits
                if status == 'partially_translated':
                    analysis_report['partially_translated_files'].append(file_info)
                    
            except Exception as e:
                error_info = {
                    'file': str(file_path),
                    'error': str(e)
                }
                analysis_report['errors'].append(error_info)
        
        # G√©n√©rer des recommandations
        analysis_report['recommendations'] = self._generate_recommendations_with_translation(analysis_report)
        
        return analysis_report
    
    def _generate_recommendations(self, report: Dict) -> List[str]:
        """G√©n√®re des recommandations bas√©es sur l'analyse."""
        recommendations = []
        
        high_score_count = len(report['by_score']['high'])
        medium_score_count = len(report['by_score']['medium'])
        
        if high_score_count > 0:
            recommendations.append(f"üéØ {high_score_count} fichier(s) tr√®s prometteur(s) d√©tect√©(s)")
            recommendations.append("üí° Commencez par traiter les fichiers avec un score √©lev√©")
        
        if medium_score_count > 0:
            recommendations.append(f"üîç {medium_score_count} fichier(s) moyennement prometteur(s)")
            recommendations.append("üí° Testez ces fichiers en mode test avant traduction compl√®te")
        
        # Recommandations par format
        for format_name, files in report['by_format'].items():
            if format_name in ['pm1_format', 'pac_format', 'pak_format'] and len(files) > 0:
                recommendations.append(f"üéÆ {len(files)} fichier(s) au format {format_name} d√©tect√©(s)")
                recommendations.append("üí° Ces formats sont typiques des jeux et m√©ritent une attention particuli√®re")
        
        if len(report['errors']) > 0:
            recommendations.append(f"‚ö†Ô∏è {len(report['errors'])} fichier(s) n'ont pas pu √™tre analys√©s")
        
        return recommendations
    
    def _generate_recommendations_with_translation(self, report: Dict) -> List[str]:
        """G√©n√®re des recommandations bas√©es sur l'analyse incluant le statut de traduction."""
        recommendations = []
        
        # Statistiques de traduction
        total_files = report['analyzed_files']
        translated_count = report['translation_summary']['fully_translated']
        untranslated_count = len(report['untranslated_files'])
        partially_translated_count = report['translation_summary']['partially_translated']
        
        # Calcul du progr√®s
        if total_files > 0:
            progress_percent = (translated_count / total_files) * 100
            recommendations.append(f"üìä Progr√®s de traduction: {progress_percent:.1f}% ({translated_count}/{total_files} fichiers)")
        
        # Recommandations bas√©es sur le progr√®s
        if untranslated_count > 0:
            recommendations.append(f"üéØ {untranslated_count} fichier(s) restant(s) √† traduire")
            recommendations.append("üí° Utilisez --auto pour traiter automatiquement les fichiers non traduits")
            
            if untranslated_count <= 5:
                recommendations.append("üèÅ Vous √™tes proche de la fin ! Quelques fichiers seulement")
            elif untranslated_count <= 20:
                recommendations.append("‚ö° Bon progr√®s ! Environ 20 fichiers ou moins √† traiter")
            else:
                recommendations.append("üöÄ Beaucoup de fichiers √† traiter, le mode automatique est recommand√©")
        else:
            recommendations.append("üéâ Tous les fichiers prometteurs semblent d√©j√† traduits !")
        
        if partially_translated_count > 0:
            recommendations.append(f"‚ö†Ô∏è {partially_translated_count} fichier(s) partiellement traduit(s)")
            recommendations.append("üí° Ces fichiers peuvent n√©cessiter une re-traduction")
        
        if translated_count > 0:
            recommendations.append(f"‚úÖ {translated_count} fichier(s) d√©j√† traduit(s) (ignor√©s automatiquement)")
        
        # Recommandations par format (inchang√©es)
        for format_name, files in report['by_format'].items():
            if format_name in ['pm1_format', 'pac_format', 'pak_format'] and len(files) > 0:
                untranslated_in_format = [f for f in files if f.get('translation_status') not in ['fully_translated']]
                if untranslated_in_format:
                    recommendations.append(f"üéÆ {len(untranslated_in_format)}/{len(files)} fichier(s) {format_name} √† traduire")
        
        if len(report['errors']) > 0:
            recommendations.append(f"‚ö†Ô∏è {len(report['errors'])} fichier(s) n'ont pas pu √™tre analys√©s")
        
        # Recommandations sp√©cifiques selon la situation
        if untranslated_count == 0 and translated_count > 0:
            recommendations.append("üéä Traduction compl√®te ! Vous pouvez relancer l'analyse pour v√©rifier")
        elif untranslated_count > 0 and translated_count > 0:
            recommendations.append("üîÑ Reprise de traduction d√©tect√©e - progression sauvegard√©e")
        
        return recommendations

class AdaptiveReinsertionManager:
    """Gestionnaire de m√©thodes de r√©insertion adaptatives selon le type de fichier."""
    
    def __init__(self):
        self.reinsertion_strategies = {
            'pm1_format': 'conservative',
            'pac_format': 'aggressive', 
            'pak_format': 'conservative',
            'bf_format': 'safe',
            'tbl_format': 'direct',
            'unknown': 'test_first',
            'text_file': 'direct'
        }
        
        self.test_results = {}
    
    def choose_strategy(self, file_format: str, file_path: Path, test_mode: bool = False) -> str:
        """
        Choisit la strat√©gie de r√©insertion optimale pour un fichier.
        """
        base_strategy = self.reinsertion_strategies.get(file_format, 'test_first')
        
        # Si on a des r√©sultats de test pour ce fichier
        if str(file_path) in self.test_results:
            test_result = self.test_results[str(file_path)]
            if test_result['success']:
                return test_result['best_strategy']
            else:
                return 'safe'  # Fallback s√©curis√©
        
        # Si mode test activ√©, toujours tester d'abord
        if test_mode:
            return 'test_first'
            
        return base_strategy
    
    def test_reinsertion_methods(self, file_path: Path, translator) -> Dict:
        """
        Teste diff√©rentes m√©thodes de r√©insertion sur un fichier et retourne les r√©sultats.
        """
        test_results = {
            'file': str(file_path),
            'methods_tested': [],
            'success': False,
            'best_strategy': 'safe',
            'details': {}
        }
        
        try:
            # Extraction pour avoir des donn√©es de test
            original_texts = translator.extract_texts(file_path)
            if not original_texts:
                test_results['details']['extraction'] = 'failed'
                return test_results
            
            test_results['details']['extraction'] = f'{len(original_texts)} texts extracted'
            
            # Cr√©er des traductions de test (courtes pour minimiser les probl√®mes)
            test_translations = []
            for text in original_texts:
                if len(text) <= 5:
                    test_translations.append(text)  # Garder les textes tr√®s courts
                elif len(text) <= 15:
                    test_translations.append(text[:len(text)-2] + ".")  # Raccourcir l√©g√®rement
                else:
                    test_translations.append(text[:len(text)//2] + "...")  # Raccourcir significativement
            
            # Tester diff√©rentes strat√©gies
            strategies_to_test = ['conservative', 'safe', 'aggressive']
            best_score = 0
            best_strategy = 'safe'
            
            for strategy in strategies_to_test:
                strategy_result = self._test_strategy(file_path, test_translations, translator, strategy)
                test_results['methods_tested'].append(strategy)
                test_results['details'][strategy] = strategy_result
                
                if strategy_result['success'] and strategy_result['score'] > best_score:
                    best_score = strategy_result['score']
                    best_strategy = strategy
                    test_results['success'] = True
            
            test_results['best_strategy'] = best_strategy
            
        except Exception as e:
            test_results['details']['error'] = str(e)
            
        return test_results
    
    def _test_strategy(self, file_path: Path, test_translations: List[str], translator, strategy: str) -> Dict:
        """Teste une strat√©gie sp√©cifique de r√©insertion."""
        result = {
            'success': False,
            'score': 0,
            'details': ''
        }
        
        # Cr√©er un fichier de test
        test_file = file_path.with_suffix(f'.test_{strategy}{file_path.suffix}')
        
        try:
            shutil.copy2(file_path, test_file)
            
            # Effectuer l'extraction sur le fichier de test d'abord
            # pour cr√©er le fichier JSON n√©cessaire
            extracted_texts = translator.extract_texts(test_file)
            if not extracted_texts:
                result['details'] = 'Extraction failed'
                return result
            
            # Sauvegarder la m√©thode actuelle
            original_method = getattr(translator, '_current_reinsertion_mode', 'default')
            
            # Appliquer la strat√©gie
            translator._current_reinsertion_mode = strategy
            
            # Tenter la r√©insertion
            success = translator.reinsert_texts(test_file, test_translations)
            
            if success:
                # V√©rifier l'int√©grit√© en extrayant √† nouveau
                new_texts = translator.extract_texts(test_file)
                
                if new_texts and len(new_texts) == len(test_translations):
                    # Calculer un score bas√© sur les changements d√©tect√©s
                    changes_detected = sum(1 for old, new in zip(test_translations, new_texts) if old != new)
                    integrity_score = len(new_texts) / len(test_translations)
                    change_score = min(1.0, changes_detected / len(test_translations))
                    
                    result['score'] = (integrity_score * 0.7) + (change_score * 0.3)
                    result['success'] = True
                    result['details'] = f'Changes: {changes_detected}/{len(test_translations)}, Integrity: {integrity_score:.2f}'
                else:
                    result['details'] = 'Integrity check failed'
            else:
                result['details'] = 'Reinsertion failed'
            
            # Restaurer la m√©thode originale
            translator._current_reinsertion_mode = original_method
            
        except Exception as e:
            result['details'] = f'Exception: {str(e)}'
        finally:
            # Nettoyage
            if test_file.exists():
                test_file.unlink()
        
        return result
    
    def apply_strategy(self, strategy: str, translator, file_path: Path, translations: List[str]) -> bool:
        """Applique une strat√©gie sp√©cifique de r√©insertion."""
        
        if strategy == 'conservative':
            return self._conservative_reinsertion(translator, file_path, translations)
        elif strategy == 'aggressive':
            return self._aggressive_reinsertion(translator, file_path, translations)
        elif strategy == 'safe':
            return self._safe_reinsertion(translator, file_path, translations)
        elif strategy == 'direct':
            return translator.reinsert_texts(file_path, translations)
        else:
            # Fallback vers la m√©thode standard
            return translator.reinsert_texts(file_path, translations)
    
    def _conservative_reinsertion(self, translator, file_path: Path, translations: List[str]) -> bool:
        """M√©thode conservative: utilise maintenant aussi le mode sans limitation."""
        # Nouvelle approche: m√™me en mode conservateur, on accepte les textes longs
        # mais on log plus d'informations pour le suivi
        logging.info(f"Mode conservateur avec r√©int√©gration compl√®te pour {file_path.name}")
        return translator.reinsert_texts(file_path, translations)
    
    def _aggressive_reinsertion(self, translator, file_path: Path, translations: List[str]) -> bool:
        """M√©thode agressive: r√©int√©gration compl√®te avec expansion de fichier si n√©cessaire."""
        # Mode agressif: accepter TOUS les textes et √©tendre le fichier si n√©cessaire
        logging.info(f"Mode agressif avec expansion automatique pour {file_path.name}")
        return translator.reinsert_texts(file_path, translations)
    
    def _safe_reinsertion(self, translator, file_path: Path, translations: List[str]) -> bool:
        """M√©thode s√ªre: cr√©e une sauvegarde et teste avant application finale."""
        # Cr√©er une sauvegarde suppl√©mentaire
        backup_file = file_path.with_suffix(file_path.suffix + f'.safe_backup_{int(time.time())}')
        shutil.copy2(file_path, backup_file)
        
        try:
            # Tenter la r√©insertion
            success = translator.reinsert_texts(file_path, translations)
            
            if success:
                # V√©rification post-r√©insertion
                new_texts = translator.extract_texts(file_path)
                if new_texts and len(new_texts) >= len(translations) * 0.8:  # Au moins 80% des textes
                    logging.info(f"R√©insertion s√ªre r√©ussie pour {file_path}")
                    return True
                else:
                    # Restaurer depuis la sauvegarde
                    shutil.copy2(backup_file, file_path)
                    logging.warning(f"R√©insertion √©chou√©e, fichier restaur√© pour {file_path}")
                    return False
            else:
                return False
                
        except Exception as e:
            # Restaurer depuis la sauvegarde en cas d'erreur
            if backup_file.exists():
                shutil.copy2(backup_file, file_path)
            logging.error(f"Erreur lors de la r√©insertion s√ªre: {e}")
            return False
        finally:
            # Nettoyage de la sauvegarde temporaire
            if backup_file.exists():
                backup_file.unlink()

class P3FESTranslator:
    def __init__(self, game_dir: str, output_dir: str):
        """
        Initialise le traducteur pour Persona 3 FES.
        
        Args:
            game_dir (str): Chemin vers le r√©pertoire du jeu
            output_dir (str): Chemin vers le r√©pertoire de sortie pour les fichiers traduits
        """
        self.game_dir = Path(game_dir)
        self.output_dir = Path(output_dir)
        self.processed_files = self._load_processed_files()
        self.supported_extensions = {'.pm1', '.pac', '.pak', '.bf', '.tbl'}
        
        # Nouveaux composants pour l'analyse automatique
        self.file_analyzer = FileAnalyzer()
        self.reinsertion_manager = AdaptiveReinsertionManager()
        self.analysis_report = None
        self._current_reinsertion_mode = 'default'
        
        # Cr√©ation des r√©pertoires n√©cessaires
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / 'extracted').mkdir(exist_ok=True)
        (self.output_dir / 'translated').mkdir(exist_ok=True)
        (self.output_dir / 'analysis').mkdir(exist_ok=True)
        
        self.special_tokens = SpecialTokens()
        
        # Initialisation du traducteur Google
        self.translator = GoogleTranslator(source='en', target='fr')
        
        # Initialisation du mod√®le Hugging Face pour l'analyse de texte
        try:
            self.text_classifier = pipeline(
                "text-classification",
                model="facebook/roberta-hate-speech-dynabench-r4-target",
                device=-1  # CPU
            )
            logging.info("Mod√®le Hugging Face charg√© avec succ√®s")
        except Exception as e:
            logging.error(f"Erreur lors du chargement du mod√®le Hugging Face: {e}")
            self.text_classifier = None

    def _load_processed_files(self) -> Dict[str, str]:
        """Charge la liste des fichiers d√©j√† trait√©s depuis le fichier log."""
        log_file = self.output_dir / 'processed_files.json'
        if log_file.exists():
            with open(log_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _save_processed_files(self):
        """Sauvegarde la liste des fichiers trait√©s dans le fichier log."""
        log_file = self.output_dir / 'processed_files.json'
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(self.processed_files, f, indent=4, ensure_ascii=False)
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """Calcule le hash SHA-256 d'un fichier."""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    
    def _is_file_modified(self, file_path: Path) -> bool:
        """V√©rifie si un fichier a √©t√© modifi√© depuis son dernier traitement."""
        if str(file_path) not in self.processed_files:
            return True
        current_hash = self._calculate_file_hash(file_path)
        return current_hash != self.processed_files[str(file_path)]
    
    def analyze_all_files(self, max_files: int = None) -> Dict:
        """
        Analyse tous les fichiers du r√©pertoire de jeu pour d√©tecter le contenu traduisible.
        """
        logging.info("üîç D√©but de l'analyse automatique des fichiers...")
        
        # Utiliser l'analyseur de fichiers
        analysis_report = self.file_analyzer.analyze_directory(self.game_dir, max_files)
        self.analysis_report = analysis_report
        
        # Sauvegarder le rapport d'analyse
        report_file = self.output_dir / 'analysis' / 'file_analysis_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_report, f, indent=2, ensure_ascii=False)
        
        logging.info(f"üìä Rapport d'analyse sauvegard√© dans {report_file}")
        
        return analysis_report
    
    def print_analysis_summary(self):
        """Affiche un r√©sum√© de l'analyse des fichiers incluant le statut de traduction."""
        if not self.analysis_report:
            print("‚ùå Aucune analyse disponible. Ex√©cutez analyze_all_files() d'abord.")
            return
        
        report = self.analysis_report
        
        print("\nüìä RAPPORT D'ANALYSE INTELLIGENT DES FICHIERS")
        print("=" * 50)
        print(f"üìÅ Fichiers analys√©s: {report['analyzed_files']}/{report['total_files']}")
        
        if report.get('ignored_files', 0) > 0:
            print(f"üö´ Fichiers .backup ignor√©s: {report['ignored_files']}")
        
        # Statistiques de traduction
        summary = report['translation_summary']
        total_with_text = sum(summary.values()) - summary['no_text'] - summary['error']
        
        if total_with_text > 0:
            print(f"\nüîÑ STATUT DE TRADUCTION:")
            if summary['fully_translated'] > 0:
                print(f"  ‚úÖ Traduits: {summary['fully_translated']} fichier(s)")
            if summary['partially_translated'] > 0:
                print(f"  üî∂ Partiellement traduits: {summary['partially_translated']} fichier(s)")
            if summary['not_translated'] > 0:
                print(f"  ‚ùå Non traduits: {summary['not_translated']} fichier(s)")
            if summary['unknown'] > 0:
                print(f"  ‚ùì Statut inconnu: {summary['unknown']} fichier(s)")
            
            # Calcul et affichage du progr√®s
            translated_count = summary['fully_translated']
            progress_percent = (translated_count / total_with_text) * 100
            progress_bar = "‚ñà" * int(progress_percent // 5) + "‚ñë" * (20 - int(progress_percent // 5))
            print(f"  üìà Progr√®s: [{progress_bar}] {progress_percent:.1f}%")
        
        print(f"\nüéØ Fichiers √† traiter: {len(report['untranslated_files'])}")
        if len(report['translated_files']) > 0:
            print(f"‚úÖ Fichiers d√©j√† traduits: {len(report['translated_files'])} (ignor√©s)")
        
        print("\nüìã R√©partition par format:")
        for format_name, files in report['by_format'].items():
            if files:
                # Compter les non-traduits par format
                untranslated_in_format = [f for f in files if f.get('translation_status') not in ['fully_translated']]
                translated_in_format = [f for f in files if f.get('translation_status') == 'fully_translated']
                
                status_info = ""
                if translated_in_format and untranslated_in_format:
                    status_info = f" ({len(untranslated_in_format)} √† faire, {len(translated_in_format)} faits)"
                elif translated_in_format:
                    status_info = f" (tous traduits)"
                elif untranslated_in_format:
                    status_info = f" (√† traduire)"
                
                print(f"  ‚Ä¢ {format_name}: {len(files)} fichier(s){status_info}")
        
        print("\nüìà R√©partition par score de confiance:")
        for score_level, files in report['by_score'].items():
            if files:
                level_names = {
                    'high': '√âlev√© (‚â•70%)',
                    'medium': 'Moyen (40-70%)',
                    'low': 'Faible (10-40%)',
                    'none': 'Tr√®s faible (<10%)'
                }
                print(f"  ‚Ä¢ {level_names.get(score_level, score_level)}: {len(files)} fichier(s)")
        
        if report['errors']:
            print(f"\n‚ö†Ô∏è Erreurs d'analyse: {len(report['errors'])}")
        
        print("\nüí° RECOMMANDATIONS:")
        for recommendation in report['recommendations']:
            print(f"  {recommendation}")
        
        # Affichage des exemples de fichiers partiellement traduits
        if report['partially_translated_files']:
            print(f"\nüîç FICHIERS PARTIELLEMENT TRADUITS:")
            for file_info in report['partially_translated_files'][:3]:  # Top 3
                examples = file_info.get('translation_examples', [])
                examples_text = ", ".join(examples[:2]) if examples else "Aucun exemple"
                print(f"  üìÑ {file_info['name']} - Confiance: {file_info['translation_confidence']:.1%}")
                print(f"      Exemples: {examples_text}")
        
        # Affichage des prochains fichiers √† traiter
        if len(report['untranslated_files']) > 0:
            print(f"\nüìã PROCHAINS FICHIERS √Ä TRAITER:")
            for file_info in sorted(report['untranslated_files'], key=lambda x: x['text_score'], reverse=True)[:5]:
                score = file_info['text_score']
                format_name = file_info['format']
                print(f"  üìÑ {file_info['name']} - Score: {score:.1%} ({format_name})")
        
        if len(report['untranslated_files']) == 0 and len(report['translated_files']) > 0:
            print(f"\nüéâ F√âLICITATIONS ! Tous les fichiers prometteurs sont traduits !")
            print(f"   Vous pouvez relancer l'analyse pour v√©rifier ou affiner les param√®tres.")
    
    def get_promising_files(self, min_score: float = 0.3, exclude_translated: bool = True) -> List[Path]:
        """
        Retourne la liste des fichiers prometteurs pour la traduction.
        
        Args:
            min_score: Score minimum pour consid√©rer un fichier comme prometteur
            exclude_translated: Si True, exclut les fichiers d√©j√† traduits
        """
        if not self.analysis_report:
            # Analyser d'abord si pas encore fait
            self.analyze_all_files()
        
        promising_files = []
        
        if exclude_translated:
            # Utiliser la liste des fichiers non traduits
            for file_info in self.analysis_report['untranslated_files']:
                if file_info['text_score'] >= min_score:
                    promising_files.append(Path(file_info['path']))
        else:
            # Utiliser l'ancienne m√©thode (tous les fichiers prometteurs)
            for file_info in self.analysis_report['promising_files']:
                if file_info['text_score'] >= min_score:
                    promising_files.append(Path(file_info['path']))
        
        return promising_files
    
    def auto_process_directory(self, test_mode: bool = True, min_score: float = 0.4):
        """
        Traite automatiquement tous les fichiers prometteurs du r√©pertoire.
        
        Args:
            test_mode: Si True, teste les m√©thodes de r√©insertion avant application
            min_score: Score minimum pour consid√©rer un fichier comme prometteur
        """
        logging.info("üöÄ D√©but du traitement automatique...")
        
        # Analyser tous les fichiers
        if not self.analysis_report:
            self.analyze_all_files()
        
        # Obtenir les fichiers prometteurs
        promising_files = self.get_promising_files(min_score)
        
        if not promising_files:
            print("‚ùå Aucun fichier prometteur d√©tect√©.")
            return
        
        print(f"üìÅ {len(promising_files)} fichier(s) s√©lectionn√©(s) pour traitement")
        
        # Statistiques
        processed_count = 0
        error_count = 0
        test_results = {}
        
        for i, file_path in enumerate(promising_files, 1):
            print(f"\nüìÑ [{i}/{len(promising_files)}] Traitement: {file_path.name}")
            
            try:
                # D√©tecter le format pour choisir la strat√©gie
                file_format, confidence = self.file_analyzer.detect_file_format(file_path)
                print(f"  üîç Format d√©tect√©: {file_format} (confiance: {confidence:.1%})")
                
                # Si mode test activ√©, tester les m√©thodes de r√©insertion
                if test_mode:
                    print(f"  üß™ Test des m√©thodes de r√©insertion...")
                    test_result = self.reinsertion_manager.test_reinsertion_methods(file_path, self)
                    test_results[str(file_path)] = test_result
                    
                    if not test_result['success']:
                        print(f"  ‚ö†Ô∏è Aucune m√©thode de r√©insertion fonctionnelle trouv√©e")
                        error_count += 1
                        continue
                    
                    print(f"  ‚úÖ Meilleure strat√©gie: {test_result['best_strategy']}")
                
                # Traitement avec la strat√©gie adapt√©e
                strategy = self.reinsertion_manager.choose_strategy(file_format, file_path, test_mode)
                print(f"  üîß Strat√©gie utilis√©e: {strategy}")
                
                if self.process_file_with_strategy(file_path, strategy):
                    processed_count += 1
                    print(f"  ‚úÖ Succ√®s")
                else:
                    error_count += 1
                    print(f"  ‚ùå √âchec")
                    
            except Exception as e:
                error_count += 1
                print(f"  ‚ùå Erreur: {e}")
                logging.error(f"Erreur lors du traitement de {file_path}: {e}")
        
        # Rapport final
        print(f"\nüìà R√âSUM√â DU TRAITEMENT AUTOMATIQUE")
        print("=" * 40)
        print(f"‚úÖ Fichiers trait√©s avec succ√®s: {processed_count}")
        print(f"‚ùå Fichiers en erreur: {error_count}")
        print(f"üìä Taux de r√©ussite: {processed_count/(processed_count+error_count)*100:.1f}%")
        
        # Sauvegarder les r√©sultats de test
        if test_results:
            test_report_file = self.output_dir / 'analysis' / 'reinsertion_test_results.json'
            with open(test_report_file, 'w', encoding='utf-8') as f:
                json.dump(test_results, f, indent=2, ensure_ascii=False)
            print(f"üìÅ R√©sultats des tests sauvegard√©s dans {test_report_file}")
    
    def process_file_with_strategy(self, file_path: Path, strategy: str) -> bool:
        """Traite un fichier avec une strat√©gie sp√©cifique."""
        try:
            # V√©rification si d√©j√† trait√©
            if not self._is_file_modified(file_path):
                logging.info(f"‚úÖ Fichier d√©j√† trait√©: {file_path.name}")
                return True
            
            logging.info(f"üîÑ D√©but du traitement avec strat√©gie '{strategy}': {file_path.name}")
            
            # Extraction
            texts = self.extract_texts(file_path)
            if not texts:
                logging.warning(f"Aucun texte extrait de {file_path}")
                return True  # Pas d'erreur, juste rien √† traduire
            
            # Traduction
            translated_texts = self.translate_texts(texts, file_path)
            
            # R√©insertion avec strat√©gie adapt√©e
            if strategy == 'default':
                success = self.reinsert_texts(file_path, translated_texts)
            else:
                success = self.reinsertion_manager.apply_strategy(strategy, self, file_path, translated_texts)
            
            if success:
                # Marquer comme trait√©
                self.processed_files[str(file_path)] = self._calculate_file_hash(file_path)
                self._save_processed_files()
                logging.info(f"‚úÖ Traitement termin√© avec succ√®s: {file_path.name}")
                return True
            else:
                logging.error(f"‚ùå √âchec de la r√©insertion: {file_path.name}")
                return False
                
        except Exception as e:
            logging.error(f"‚ùå Erreur lors du traitement de {file_path}: {e}")
            return False
    
    def extract_texts(self, file_path: Path) -> Optional[List[str]]:
        """
        Extraction simple et robuste des textes pour tous les formats support√©s.
        """
        # Nouveau syst√®me: pas de v√©rification d'extension, on teste tous les fichiers
        out_json = self.output_dir / 'extracted' / (file_path.stem + '.json')

        try:
            with open(file_path, 'rb') as f:
                data = f.read()

            messages = []
            texts = []
            
            # Patterns multiples pour une meilleure extraction
            patterns = [
                rb'[\x20-\x7E\x80-\xFF]{8,}',  # Cha√Ænes ASCII √©tendues
                rb'[\x20-\x7E]{4,}',           # Cha√Ænes ASCII standard
            ]
            
            all_matches = set()
            for pattern in patterns:
                matches = re.finditer(pattern, data)
                for match in matches:
                    if match.group() not in all_matches:
                        all_matches.add(match.group())
                        
                        # Essayer plusieurs encodages
                        text = None
                        for encoding in ['ascii', 'shift_jis', 'utf-8', 'latin1']:
                            try:
                                text = match.group().decode(encoding).strip()
                                if len(text) >= 4 and self._is_likely_game_text(text):
                                    break
                                text = None
                            except:
                                continue
                        
                        if text:
                            offset = match.start()
                            messages.append({
                                'offset': offset,
                                'raw': match.group().hex(),
                                'encoding': encoding,
                                'texts': [text]
                            })
                            texts.append(text)

            # Sauvegarde des messages extraits
            with open(out_json, 'w', encoding='utf-8') as f:
                json.dump(messages, f, ensure_ascii=False, indent=2)
            
            logging.info(f"{len(texts)} textes extraits de {file_path}")
            return texts

        except Exception as e:
            logging.error(f"Erreur extraction: {e}")
            return None
    
    def _is_likely_game_text(self, text: str) -> bool:
        """D√©termine si le texte ressemble √† du texte de jeu traduisible."""
        # Filtres de base
        if len(text.strip()) < 4:
            return False
            
        # Ignore les cha√Ænes qui ne contiennent que des caract√®res sp√©ciaux
        if not any(c.isalpha() for c in text):
            return False
            
        # Ignore les cha√Ænes avec trop de caract√®res r√©p√©t√©s
        if len(set(text)) < len(text) / 3:
            return False
            
        # Ignore les chemins de fichiers √©vidents
        if '/' in text or '\\' in text or text.endswith('.exe'):
            return False
            
        return True

    def translate_texts(self, texts: List[str], file_path: Path = None) -> List[str]:
        """
        Traduit les textes de l'anglais vers le fran√ßais avec Google Translator.
        """
        import time
        import json
        import re
        import sys

        # Liste blanche personnalisable de noms propres √† ne jamais traduire
        whitelist = [
            "Yukari", "Mitsuru", "Fuuka", "Akihiko", "Tartarus", "Nyx", "SEES", "Aigis", "Junpei", "Shinjiro", "Koromaru", "Elizabeth", "Igor", "Pharos", "Ryoji", "Chidori", "Strega", "Ikutsuki", "Takaya", "Jin", "Ken", "Persona", "Evoker", "S.E.E.S.", "Aragaki", "Makoto", "Minato", "Protagonist", "Yamagishi", "Sanada", "Takeba", "Iori", "Amada", "Tanaka", "Velvet Room", "Paulownia Mall", "Gekkoukan", "Mitsuru Kirijo", "Yukari Takeba", "Fuuka Yamagishi", "Akihiko Sanada", "Junpei Iori", "Shinjiro Aragaki", "Ken Amada", "Koromaru", "Aigis", "Elizabeth", "Igor", "Pharos", "Ryoji Mochizuki", "Chidori", "Takaya", "Jin", "Ikutsuki", "Strega", "Nyx Avatar", "Nyx", "Tartarus", "SEES", "Persona", "Evoker", "S.E.E.S."
        ]

        translated = []
        
        try:
            total_texts = len(texts)
            
            for i, text in enumerate(texts, 1):
                self.print_progress(i, total_texts, text)
                
                # Extraction des tokens et du texte propre
                tokens, clean_text = self.special_tokens.extract_game_tokens(text)
                
                # R√©cup√©ration du contexte
                previous_text = texts[i-2] if i > 1 else None
                next_text = texts[i] if i < len(texts) else None
                
                if not clean_text.strip() or self.should_skip_translation(text, whitelist, previous_text, next_text):
                    translated.append(text)
                    continue
                    
                try:
                    # Traduction avec Google Translate
                    fr = self.translator.translate(clean_text)
                    if not fr:  # Si la traduction √©choue
                        logging.warning(f"√âchec de la traduction pour '{text}', retour au texte original")
                        fr = text
                except Exception as e:
                    logging.error(f"Erreur lors de la traduction de '{text}': {e}")
                    fr = text
                
                # Reconstruction avec les tokens originaux
                fr = self.special_tokens.reconstruct_text(fr, tokens)
                translated.append(fr)
                time.sleep(0.5)  # Pause pour respecter les limites d'API
            
            print()

        except Exception as e:
            logging.error(f"Erreur lors de la traduction : {e}")
            return texts

        # Sauvegarde dans un fichier √† part si file_path est fourni
        if file_path is not None:
            out_json = self.output_dir / 'translated' / (file_path.stem + '_fr.json')
            try:
                with open(out_json, 'w', encoding='utf-8') as f:
                    json.dump(translated, f, ensure_ascii=False, indent=2)
                logging.info(f"Textes traduits sauvegard√©s dans {out_json}")
            except Exception as e:
                logging.error(f"Erreur lors de la sauvegarde des textes traduits : {e}")
        
        return translated
    
    def reinsert_texts(self, file_path, translated_texts: List[str]) -> bool:
        """
        R√©ins√®re les textes traduits dans le fichier original de mani√®re s√©curis√©e.
        Version simplifi√©e et robuste.
        """
        import json
        import shutil
        
        # S'assurer que file_path est un Path object
        if isinstance(file_path, str):
            file_path = Path(file_path)
        elif not isinstance(file_path, Path):
            file_path = Path(str(file_path))
        
        # Cr√©ation du dossier de sortie
        output_dir = self.output_dir / 'reinjected'
        output_dir.mkdir(exist_ok=True)
        out_file = output_dir / file_path.name
        
        try:
            # Chargement du fichier d'extraction
            extracted_json = self.output_dir / 'extracted' / (file_path.stem + '.json')
            if not extracted_json.exists():
                logging.error(f"Fichier d'extraction manquant : {extracted_json}")
                return False
                
            with open(extracted_json, 'r', encoding='utf-8') as f:
                messages = json.load(f)
                
            if len(messages) != len(translated_texts):
                logging.error(f"Nombre de textes traduits ({len(translated_texts)}) != messages extraits ({len(messages)})")
                return False
            
            # Lecture du fichier original
            with open(file_path, 'rb') as f:
                data = bytearray(f.read())
            
            # Pr√©paration des remplacements (en ordre inverse pour ne pas d√©caler les offsets)
            replacements = []
            for msg, new_text in zip(messages, translated_texts):
                if 'offset' in msg and 'texts' in msg and msg['texts']:
                    old_text = msg['texts'][0]
                    
                    # Essai de diff√©rents encodages pour le texte original
                    old_bytes = None
                    used_encoding = 'utf-8'  # Commencer par UTF-8 pour supporter les caract√®res fran√ßais
                    for encoding in ['utf-8', 'ascii', 'shift_jis', 'latin1']:
                        try:
                            test_bytes = old_text.encode(encoding)
                            if data.find(test_bytes) != -1:
                                old_bytes = test_bytes
                                used_encoding = encoding
                                break
                        except:
                            continue
                    
                    if old_bytes is None:
                        logging.warning(f"Impossible de trouver '{old_text}' dans le fichier")
                        continue
                    
                    # Encodage du nouveau texte avec le m√™me encodage
                    try:
                        new_bytes = new_text.encode(used_encoding)
                    except UnicodeEncodeError:
                        # Si l'encodage original ne supporte pas le fran√ßais, essayer UTF-8
                        try:
                            new_bytes = new_text.encode('utf-8')
                            used_encoding = 'utf-8'
                            logging.info(f"Passage en UTF-8 pour '{new_text}' (caract√®res fran√ßais d√©tect√©s)")
                        except:
                            logging.warning(f"Impossible d'encoder '{new_text}', utilisation de l'original")
                            new_bytes = old_bytes
                    
                    # STRAT√âGIE SANS LIMITATION: R√©int√©grer TOUS les textes peu importe la taille
                    if len(new_bytes) > len(old_bytes):
                        # Aucune limitation ! Traduction compl√®te avec expansion automatique
                        overflow = len(new_bytes) - len(old_bytes)
                        expansion_percent = (overflow / len(old_bytes)) * 100
                        logging.info(f"üöÄ Expansion automatique: '{old_text}' -> '{new_text}' (+{overflow} bytes, +{expansion_percent:.1f}%)")
                        # new_bytes reste inchang√© - expansion compl√®te garantie !
                        
                    elif len(new_bytes) < len(old_bytes):
                        # Padding avec des espaces ou des z√©ros
                        if used_encoding in ['ascii', 'utf-8', 'latin1']:
                            padding_char = b' '
                        else:
                            padding_char = b'\x00'
                        new_bytes = new_bytes + padding_char * (len(old_bytes) - len(new_bytes))
                    
                    # Recherche de la position du texte original
                    offset = data.find(old_bytes)
                    if offset != -1:
                        replacements.append({
                            'offset': offset,
                            'old_bytes': old_bytes,
                            'new_bytes': new_bytes
                        })
                    else:
                        logging.warning(f"Texte original non trouv√© dans le fichier: '{old_text}'")
            
            # Application des remplacements avec gestion dynamique de la taille
            replacements.sort(key=lambda x: x['offset'], reverse=True)
            successful_replacements = 0
            total_size_change = 0
            
            for replacement in replacements:
                offset = replacement['offset']
                old_bytes = replacement['old_bytes']
                new_bytes = replacement['new_bytes']
                
                # Ajuster l'offset si des remplacements pr√©c√©dents ont chang√© la taille
                adjusted_offset = offset + total_size_change
                
                # V√©rification de s√©curit√© avec offset ajust√©
                if adjusted_offset >= 0 and adjusted_offset + len(old_bytes) <= len(data):
                    if data[adjusted_offset:adjusted_offset+len(old_bytes)] == old_bytes:
                        # Calculer le changement de taille
                        size_diff = len(new_bytes) - len(old_bytes)
                        
                        # Remplacer avec la nouvelle taille (peut √™tre plus grande !)
                        data[adjusted_offset:adjusted_offset+len(old_bytes)] = new_bytes
                        
                        # Mettre √† jour le changement total de taille
                        total_size_change += size_diff
                        successful_replacements += 1
                        
                        if size_diff > 0:
                            logging.info(f"‚úÖ Remplacement √©tendu r√©ussi √† l'offset {adjusted_offset} (+{size_diff} bytes)")
                        else:
                            logging.debug(f"Remplacement r√©ussi √† l'offset {adjusted_offset}")
                    else:
                        logging.warning(f"Donn√©es √† l'offset {adjusted_offset} ne correspondent pas, remplacement ignor√©")
                else:
                    logging.warning(f"Offset {adjusted_offset} hors limites, remplacement ignor√©")
            
            logging.info(f"üìä {successful_replacements}/{len(replacements)} remplacements r√©ussis, taille finale: {len(data)} bytes")
            
            # Sauvegarde du fichier modifi√©
            with open(out_file, 'wb') as f:
                f.write(data)
            logging.info(f"Fichier r√©inject√© sauvegard√© : {out_file}")
            
            # Copie de s√©curit√© de l'original (si ce n'est pas d√©j√† fait)
            backup_file = file_path.with_suffix(file_path.suffix + '.backup')
            if not backup_file.exists():
                shutil.copy2(file_path, backup_file)
                logging.info(f"Sauvegarde cr√©√©e : {backup_file}")
            
            # Remplacement du fichier original
            try:
                shutil.copy2(out_file, file_path)
                logging.info(f"Fichier original mis √† jour : {file_path}")
                return True
            except Exception as e:
                logging.error(f"Erreur lors de la mise √† jour du fichier original : {e}")
                logging.info(f"Le fichier traduit est disponible dans : {out_file}")
                return False
                
        except Exception as e:
            logging.error(f"Erreur lors de la r√©insertion : {e}")
            return False
    
    def validate_integration_quality(self, file_path: Path) -> Dict:
        """
        Valide la qualit√© de l'int√©gration apr√®s r√©insertion.
        Retourne un rapport d√©taill√©.
        """
        try:
            # Extraire les textes du fichier modifi√©
            new_texts = self.extract_texts(file_path)
            
            # Analyser le statut de traduction
            translation_status = self.file_analyzer.detect_translation_status(file_path)
            
            # Statistiques
            validation_report = {
                'file': str(file_path),
                'texts_found': len(new_texts) if new_texts else 0,
                'translation_status': translation_status['status'],
                'french_ratio': translation_status['confidence'],
                'quality_score': 0.0,
                'recommendations': []
            }
            
            # Calculer le score de qualit√©
            if new_texts and len(new_texts) > 0:
                # Compter les textes fran√ßais vs anglais
                french_count = translation_status.get('french_indicators', 0)
                english_count = translation_status.get('english_indicators', 0)
                total_indicators = french_count + english_count
                
                if total_indicators > 0:
                    french_ratio = french_count / total_indicators
                    validation_report['quality_score'] = french_ratio
                    
                    if french_ratio >= 0.8:
                        validation_report['recommendations'].append("‚úÖ Excellente qualit√© de traduction")
                    elif french_ratio >= 0.5:
                        validation_report['recommendations'].append("‚úÖ Bonne qualit√© de traduction")  
                    elif french_ratio >= 0.2:
                        validation_report['recommendations'].append("‚ö†Ô∏è Traduction partielle d√©tect√©e")
                    else:
                        validation_report['recommendations'].append("‚ùå Peu de traductions d√©tect√©es")
                else:
                    validation_report['recommendations'].append("‚ÑπÔ∏è Aucun indicateur de langue d√©tect√©")
            else:
                validation_report['recommendations'].append("‚ö†Ô∏è Aucun texte extrait du fichier")
            
            # V√©rifier la taille du fichier
            file_size = file_path.stat().st_size
            validation_report['file_size'] = file_size
            
            if file_size > 1024 * 1024:  # > 1MB
                validation_report['recommendations'].append(f"üìä Fichier volumineux: {file_size // 1024}KB (expansion r√©ussie)")
            
            return validation_report
            
        except Exception as e:
            return {
                'file': str(file_path),
                'error': str(e),
                'quality_score': 0.0,
                'recommendations': [f"‚ùå Erreur de validation: {e}"]
            }
    
    def process_file(self, file_path: Path) -> bool:
        """Traite un fichier complet (extraction, traduction, r√©insertion)."""
        # V√©rification si le fichier a d√©j√† √©t√© trait√©
        if not self._is_file_modified(file_path):
            logging.info(f"‚úÖ Fichier d√©j√† trait√© et non modifi√©: {file_path.name}")
            return True
            
        logging.info(f"üîÑ D√©but du traitement: {file_path.name}")
        
        try:
            # √âtape 1: Extraction
            logging.info(f"  üì§ Extraction des textes...")
            texts = self.extract_texts(file_path)
            if texts is None:
                logging.error(f"  ‚ùå √âchec de l'extraction")
                return False
                
            # V√©rification si le fichier contient des textes √† traduire
            if not texts:
                logging.info(f"  ‚ÑπÔ∏è Aucun texte √† traduire trouv√©, fichier marqu√© comme trait√©")
                # Enregistrer le fichier comme trait√© m√™me s'il n'y a pas de textes
                self.processed_files[str(file_path)] = self._calculate_file_hash(file_path)
                self._save_processed_files()
                return True
            
            logging.info(f"  üìù {len(texts)} texte(s) extrait(s)")
            
            # √âtape 2: Traduction
            logging.info(f"  üîÑ Traduction en cours...")
            translated_texts = self.translate_texts(texts, file_path)
            
            # √âtape 3: R√©insertion
            logging.info(f"  üì• R√©insertion des textes traduits...")
            if not self.reinsert_texts(file_path, translated_texts):
                logging.error(f"  ‚ùå √âchec de la r√©insertion")
                return False
            
            # √âtape 4: Validation de la qualit√©
            logging.info(f"  üîç Validation de la qualit√© d'int√©gration...")
            validation = self.validate_integration_quality(file_path)
            
            quality_score = validation['quality_score']
            logging.info(f"  üìä Score de qualit√©: {quality_score:.1%}")
            
            for recommendation in validation['recommendations']:
                logging.info(f"  {recommendation}")
            
            if quality_score >= 0.5:
                logging.info(f"  ‚úÖ Qualit√© d'int√©gration valid√©e")
            else:
                logging.warning(f"  ‚ö†Ô∏è Qualit√© d'int√©gration √† v√©rifier manuellement")
            
            logging.info(f"  ‚úÖ Traitement termin√© avec succ√®s")
            
            # Mise √† jour du hash du fichier
            self.processed_files[str(file_path)] = self._calculate_file_hash(file_path)
            self._save_processed_files()
            return True
            
        except Exception as e:
            logging.error(f"  ‚ùå Erreur lors du traitement de {file_path.name}: {str(e)}")
            return False
    
    def process_directory(self):
        """Traite tous les fichiers du r√©pertoire du jeu avec l'ancienne m√©thode."""
        print("üîÑ Mode de traitement traditionnel activ√©...")
        print("üí° Utilisez --auto pour le nouveau mode d'analyse automatique")
        
        processed_count = 0
        error_count = 0
        ignored_count = 0
        
        # Recherche de tous les fichiers support√©s (ancienne m√©thode)
        all_files = []
        for root, _, files in os.walk(self.game_dir):
            for file in files:
                file_path = Path(root) / file
                # Ignorer les fichiers .backup
                if file_path.suffix.lower() == '.backup' or '.backup' in file_path.name:
                    ignored_count += 1
                    continue
                if file_path.suffix.lower() in self.supported_extensions:
                    all_files.append(file_path)
        
        if not all_files:
            print(f"‚ùå Aucun fichier support√© trouv√© dans {self.game_dir}")
            print(f"üìÅ Extensions support√©es: {', '.join(self.supported_extensions)}")
            if ignored_count > 0:
                print(f"üö´ {ignored_count} fichier(s) .backup ignor√©(s)")
            return
            
        print(f"üìä {len(all_files)} fichier(s) trouv√©(s) √† traiter")
        if ignored_count > 0:
            print(f"üö´ {ignored_count} fichier(s) .backup ignor√©(s)")
        
        for i, file_path in enumerate(all_files, 1):
            print(f"\nüìÑ [{i}/{len(all_files)}] Traitement: {file_path.name}")
            try:
                if self.process_file(file_path):
                    processed_count += 1
                    print(f"‚úÖ Succ√®s")
                else:
                    error_count += 1
                    print(f"‚ùå √âchec")
            except Exception as e:
                error_count += 1
                print(f"‚ùå Erreur: {e}")
                
        print(f"\nüìà R√©sum√©: {processed_count} r√©ussis, {error_count} √©checs")
    
    def test_mode(self):
        """Mode test pour analyser les fichiers sans traduction."""
        print("üß™ Mode test activ√© - Analyse des fichiers...")
        
        for root, _, files in os.walk(self.game_dir):
            for file in files:
                file_path = Path(root) / file
                if file_path.suffix.lower() in self.supported_extensions:
                    print(f"\nüìÑ Analyse: {file_path}")
                    
                    try:
                        texts = self.extract_texts(file_path)
                        if texts:
                            print(f"  üìù {len(texts)} texte(s) extrait(s)")
                            # Afficher les premiers textes
                            for i, text in enumerate(texts[:5]):
                                print(f"    {i+1}. {text[:60]}...")
                            if len(texts) > 5:
                                print(f"    ... et {len(texts)-5} autre(s)")
                        else:
                            print(f"  ‚ùå Aucun texte extrait")
                    except Exception as e:
                        print(f"  ‚ùå Erreur: {e}")

    def print_progress(self, current: int, total: int, text: str):
        """Affiche la progression de la traduction avec le texte en cours."""
        progress = (current / total) * 100
        sys.stdout.write(f"\rTraduction en cours : {progress:.1f}% - Texte {current}/{total}: {text[:50]}...")
        sys.stdout.flush()

    def should_skip_translation(self, text: str, whitelist: List[str], previous_text: str = None, next_text: str = None) -> bool:
        """Version simplifi√©e qui traduit plus de textes."""
        clean_text = text.strip()
        
        # Si le texte est vide
        if not clean_text:
            return True
            
        # Si le texte est dans la whitelist des noms propres
        if any(name.lower() in clean_text.lower() for name in whitelist):
            return False  # On traduit quand m√™me pour le contexte
            
        # Patterns vraiment critiques √† ignorer
        skip_patterns = [
            r'^\d+$',                    # Nombres seuls
            r'^[A-Z0-9_]{6,}$',         # Codes longs en majuscules
            r'^[\x00-\x1F]+$',          # Caract√®res de contr√¥le
            r'^[!@#$%^&*()_+\-=\[\]{};\'"\\|,.<>\/?]+$',  # Que des symboles
        ]
        
        for pattern in skip_patterns:
            if re.match(pattern, clean_text):
                return True
        
        # Si c'est trop court et sans voyelles
        if len(clean_text) < 3 and not any(v in clean_text.lower() for v in 'aeiouy'):
            return True
            
        return False

def main():
    """Point d'entr√©e principal du programme."""
    import argparse
    import sys
    
    parser = argparse.ArgumentParser(description='Traducteur automatique pour Persona 3 FES')
    parser.add_argument('--game-dir', default='GameFiles', help='Dossier contenant les fichiers du jeu')
    parser.add_argument('--output-dir', default='TranslatedFiles', help='Dossier de sortie')
    parser.add_argument('--file', help='Traduire un fichier sp√©cifique')
    parser.add_argument('--test', action='store_true', help='Mode test (analyse sans traduction)')
    parser.add_argument('--verbose', action='store_true', help='Mode verbose')
    
    # Nouvelles options pour l'analyse automatique
    parser.add_argument('--analyze', action='store_true', help='Analyser tous les fichiers pour d√©tecter le contenu traduisible')
    parser.add_argument('--auto', action='store_true', help='Mode automatique: analyse + traitement intelligent')
    parser.add_argument('--auto-test', action='store_true', help='Mode automatique avec test des m√©thodes de r√©insertion')
    parser.add_argument('--min-score', type=float, default=0.4, help='Score minimum pour consid√©rer un fichier (0.0-1.0)')
    parser.add_argument('--max-files', type=int, help='Limite le nombre de fichiers √† analyser')
    parser.add_argument('--remaining', action='store_true', help='Affiche seulement les fichiers restants √† traduire')
    parser.add_argument('--progress', action='store_true', help='Affiche le progr√®s de traduction et statistiques d√©taill√©es')
    parser.add_argument('--validate', action='store_true', help='Valide la qualit√© des traductions dans les fichiers existants')
    parser.add_argument('--validate-file', help='Valide la qualit√© de traduction d\'un fichier sp√©cifique')
    
    # Nouvelle option pour la strat√©gie de traduction
    parser.add_argument('--strategy', choices=['professional', 'preserve', 'mixed'], 
                       default='professional', 
                       help='Strat√©gie pour g√©rer les traductions trop longues (d√©faut: professional)')
    parser.add_argument('--show-strategies', action='store_true', 
                       help='Affiche les strat√©gies disponibles et leurs descriptions')
    
    args = parser.parse_args()
    
    # Afficher les strat√©gies disponibles si demand√©
    if args.show_strategies:
        print("üéØ Strat√©gies de Traduction:")
        print("=" * 40)
        print("üìã AGGRESSIVE - Aucune limitation de taille")
        print("   R√©int√®gre TOUS les textes peu importe leur longueur")
        print("   ‚Ä¢ Pr√©serve la qualit√©: ‚úÖ")
        print("   ‚Ä¢ Traductions compl√®tes: ‚úÖ") 
        print("   ‚Ä¢ Aucune troncature: ‚úÖ")
        print(f"\nüí° Mode actuel: R√©int√©gration sans limitation")
        return
    
    print(f"üéÆ Strat√©gie de traduction: {args.strategy.upper()}")
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # V√©rification que le dossier de jeu existe
    if not Path(args.game_dir).exists():
        print(f"‚ùå Erreur: Le dossier '{args.game_dir}' n'existe pas.")
        print(f"üìÅ Cr√©ez le dossier et placez-y vos fichiers .pm1, .pac, .pak, .bf, .tbl")
        sys.exit(1)
    
    try:
        translator = P3FESTranslator(args.game_dir, args.output_dir)
        
        if args.file:
            # Traitement d'un fichier sp√©cifique
            file_path = Path(args.file)
            if file_path.exists():
                print(f"üîÑ Traitement du fichier: {file_path}")
                success = translator.process_file(file_path)
                print(f"‚úÖ Succ√®s" if success else f"‚ùå √âchec")
            else:
                print(f"‚ùå Fichier non trouv√©: {file_path}")
                
        elif args.analyze:
            # Mode analyse seulement
            print("üîç Mode analyse - D√©tection des fichiers traduisibles...")
            analysis_report = translator.analyze_all_files(args.max_files)
            translator.print_analysis_summary()
            
        elif args.remaining:
            # Mode affichage des fichiers restants
            print("üìã Analyse des fichiers restants √† traduire...")
            analysis_report = translator.analyze_all_files(args.max_files)
            
            remaining_files = translator.get_promising_files(args.min_score, exclude_translated=True)
            translated_files = len(analysis_report.get('translated_files', []))
            
            print(f"\nüìä FICHIERS RESTANTS √Ä TRADUIRE")
            print("=" * 35)
            print(f"‚úÖ Fichiers d√©j√† traduits: {translated_files}")
            print(f"üéØ Fichiers restants: {len(remaining_files)}")
            
            if remaining_files:
                print(f"\nüìã LISTE DES FICHIERS √Ä TRADUIRE:")
                for i, file_path in enumerate(remaining_files, 1):
                    # Obtenir les infos d√©taill√©es
                    file_info = None
                    for info in analysis_report['untranslated_files']:
                        if Path(info['path']) == file_path:
                            file_info = info
                            break
                    
                    if file_info:
                        score = file_info['text_score']
                        format_name = file_info['format']
                        size_kb = file_info['size'] // 1024
                        print(f"  {i:2d}. {file_path.name}")
                        print(f"      Score: {score:.1%} | Format: {format_name} | Taille: {size_kb}KB")
                    else:
                        print(f"  {i:2d}. {file_path.name}")
                
                estimated_time = len(remaining_files) * 2  # 2 minutes par fichier en moyenne
                print(f"\n‚è±Ô∏è Temps estim√©: ~{estimated_time} minutes")
                print(f"üí° Commande recommand√©e: python p3fes_translator.py --auto-test")
            else:
                print(f"\nüéâ F√âLICITATIONS ! Tous les fichiers semblent d√©j√† traduits !")
                
        elif args.progress:
            # Mode affichage du progr√®s d√©taill√©
            print("üìà Analyse du progr√®s de traduction...")
            analysis_report = translator.analyze_all_files(args.max_files)
            
            summary = analysis_report['translation_summary']
            total_files = analysis_report['analyzed_files']
            translated = summary['fully_translated']
            partial = summary['partially_translated']
            untranslated = summary['not_translated']
            
            print(f"\nüìä PROGR√àS DE TRADUCTION D√âTAILL√â")
            print("=" * 40)
            print(f"üìÅ Total des fichiers: {total_files}")
            print(f"‚úÖ Traduits: {translated} ({translated/total_files*100:.1f}%)")
            print(f"üî∂ Partiellement: {partial} ({partial/total_files*100:.1f}%)")
            print(f"‚ùå Non traduits: {untranslated} ({untranslated/total_files*100:.1f}%)")
            
            # Barre de progr√®s ASCII
            progress_percent = (translated / total_files) * 100 if total_files > 0 else 0
            bar_length = 30
            filled_length = int(bar_length * translated // total_files) if total_files > 0 else 0
            bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)
            print(f"\nüìà [{bar}] {progress_percent:.1f}%")
            
            # Statistiques par format
            print(f"\nüìã PROGR√àS PAR FORMAT:")
            for format_name, files in analysis_report['by_format'].items():
                if files:
                    format_translated = len([f for f in files if f.get('translation_status') == 'fully_translated'])
                    format_total = len(files)
                    format_percent = (format_translated / format_total * 100) if format_total > 0 else 0
                    print(f"  ‚Ä¢ {format_name}: {format_translated}/{format_total} ({format_percent:.1f}%)")
            
            remaining_count = len(analysis_report.get('untranslated_files', []))
            if remaining_count > 0:
                print(f"\nüéØ {remaining_count} fichier(s) restant(s) √† traiter")
                print(f"üí° Utilisez --remaining pour voir la liste d√©taill√©e")
            
        elif args.validate:
            # Mode validation de qualit√©
            print("üîç Validation de la qualit√© des traductions existantes...")
            analysis_report = translator.analyze_all_files(args.max_files)
            
            # Valider seulement les fichiers traduits
            translated_files = analysis_report.get('translated_files', [])
            
            if not translated_files:
                print("‚ùå Aucun fichier traduit d√©tect√© pour validation")
            else:
                print(f"üìä Validation de {len(translated_files)} fichier(s) traduit(s)...")
                
                total_quality = 0.0
                validated_count = 0
                
                for file_info in translated_files:
                    file_path = Path(file_info['path'])
                    print(f"\nüìÑ Validation: {file_path.name}")
                    
                    validation = translator.validate_integration_quality(file_path)
                    quality = validation['quality_score']
                    
                    print(f"  üìä Score de qualit√©: {quality:.1%}")
                    for rec in validation['recommendations']:
                        print(f"  {rec}")
                    
                    total_quality += quality
                    validated_count += 1
                
                if validated_count > 0:
                    avg_quality = total_quality / validated_count
                    print(f"\nüìà R√âSUM√â DE VALIDATION:")
                    print(f"  üìä Qualit√© moyenne: {avg_quality:.1%}")
                    print(f"  üìÅ Fichiers valid√©s: {validated_count}")
                    
                    if avg_quality >= 0.8:
                        print(f"  üéâ Excellente qualit√© globale !")
                    elif avg_quality >= 0.6:
                        print(f"  ‚úÖ Bonne qualit√© globale")
                    else:
                        print(f"  ‚ö†Ô∏è Qualit√© √† am√©liorer")
                        
        elif args.validate_file:
            # Validation d'un fichier sp√©cifique
            file_path = Path(args.validate_file)
            if file_path.exists():
                print(f"üîç Validation de la qualit√©: {file_path}")
                validation = translator.validate_integration_quality(file_path)
                
                print(f"üìä Score de qualit√©: {validation['quality_score']:.1%}")
                print(f"üìù Textes trouv√©s: {validation['texts_found']}")
                print(f"üîÑ Statut: {validation['translation_status']}")
                
                print(f"\nüí° Recommandations:")
                for rec in validation['recommendations']:
                    print(f"  {rec}")
            else:
                print(f"‚ùå Fichier non trouv√©: {file_path}")
            
        elif args.auto or args.auto_test:
            # Mode automatique
            test_mode = args.auto_test
            print(f"ü§ñ Mode automatique {'avec tests' if test_mode else 'standard'}")
            translator.auto_process_directory(test_mode=test_mode, min_score=args.min_score)
            
        elif args.test:
            # Mode test traditionnel
            print("üß™ Mode test - Analyse des fichiers sans traduction...")
            translator.test_mode()
            
        else:
            # Mode traditionnel
            print("üöÄ Mode traditionnel - Traitement des fichiers par extension...")
            translator.process_directory()
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        logging.error(f"Erreur fatale: {e}")
        print(f"‚ùå Erreur fatale: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()