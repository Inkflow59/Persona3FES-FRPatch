#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import logging
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import shutil
from datetime import datetime, timedelta
from deep_translator import GoogleTranslator
import requests
import time
import re
import sys
import subprocess
from dotenv import load_dotenv
from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer
import struct
import mimetypes
from collections import defaultdict, Counter
import sqlite3
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache

# Interface graphique optionnelle
try:
    import tkinter as tk
    from tkinter import ttk, filedialog, messagebox
    GUI_AVAILABLE = True
except ImportError:
    GUI_AVAILABLE = False
    logging.warning("Interface graphique non disponible (tkinter manquant)")

# Chargement des variables d'environnement
load_dotenv()

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('translation.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class SpecialTokens:
    """Gestion des tokens sp√©ciaux pour Persona 3 FES."""
    
    # Tokens de formatage du jeu (codes de contr√¥le)
    GAME_FORMAT_TOKENS = {
        # Codes de formatage de texte
        r'\{F[0-9A-F]{2}\s+[0-9A-F]{2}\s+[0-9A-F]{2}\s+[0-9A-F]{2}\}': 'GAME_FORMAT_1',  # {F2 08 FF FF}
        r'\{F[0-9A-F]{2}\s+[0-9A-F]{2}\}': 'GAME_FORMAT_2',  # {F1 3F}
        r'\{[0-9A-F]{2}\}': 'GAME_FORMAT_3',  # {0A}
        r'\{00\}': 'GAME_END',  # Fin de message
        
        # Codes de dialogue et d'interface
        r'\{NAME\d+\}': 'PLAYER_NAME',  # Nom du joueur
        r'\{ITEM\d+\}': 'ITEM_NAME',  # Nom d'objet
        r'\{PERSONA\d+\}': 'PERSONA_NAME',  # Nom de Persona
        r'\{SKILL\d+\}': 'SKILL_NAME',  # Nom de comp√©tence
        r'\{LOCATION\d+\}': 'LOCATION_NAME',  # Nom de lieu
        
        # Codes de formatage avanc√©s
        r'\{COLOR\d+\}': 'TEXT_COLOR',  # Couleur du texte
        r'\{SPEED\d+\}': 'TEXT_SPEED',  # Vitesse d'affichage
        r'\{WAIT\d+\}': 'TEXT_WAIT',  # Pause dans le texte
        r'\{CLEAR\}': 'CLEAR_TEXT',  # Effacer le texte
        r'\{WINDOW\d+\}': 'WINDOW_TYPE',  # Type de fen√™tre
        
        # Codes de son et d'animation
        r'\{SOUND\d+\}': 'SOUND_EFFECT',  # Effet sonore
        r'\{VOICE\d+\}': 'VOICE_LINE',  # Ligne vocale
        r'\{ANIM\d+\}': 'ANIMATION',  # Animation
        r'\{FACE\d+\}': 'FACE_EMOTION',  # Expression faciale
        
        # Codes de menu et de choix
        r'\{CHOICE\d+\}': 'MENU_CHOICE',  # Option de menu
        r'\{YESNO\}': 'YES_NO_PROMPT',  # Prompt Oui/Non
        r'\{INPUT\}': 'TEXT_INPUT',  # Saisie de texte
        r'\{CURSOR\d+\}': 'CURSOR_POS',  # Position du curseur
        
        # Codes de statut et de combat
        r'\{HP\d+\}': 'HP_VALUE',  # Points de vie
        r'\{SP\d+\}': 'SP_VALUE',  # Points de magie
        r'\{STATUS\d+\}': 'STATUS_EFFECT',  # Effet de statut
        r'\{DAMAGE\d+\}': 'DAMAGE_VALUE',  # Valeur de d√©g√¢ts
    }
    
    # Tokens de formatage standard
    FORMAT_TOKENS = {
        '\n': 'NEWLINE',
        '\t': 'TAB',
        '\r': 'CARRIAGE_RETURN',
        '\\n': 'NEWLINE_ESC',
        '\\t': 'TAB_ESC',
        '\\r': 'CARRIAGE_RETURN_ESC',
        '„Äå': 'DIALOG_START',  # Guillemets japonais pour dialogue
        '„Äç': 'DIALOG_END',
        '„Äé': 'THOUGHT_START',  # Guillemets japonais pour pens√©es
        '„Äè': 'THOUGHT_END'
    }
    
    # Tokens de commande
    COMMAND_TOKENS = {
        'MSG_': 'MESSAGE_ID',
        'CMD_': 'COMMAND_ID',
        'EVT_': 'EVENT_ID',
        'SCENE_': 'SCENE_ID',
        'BATTLE_': 'BATTLE_ID',
        'QUEST_': 'QUEST_ID'
    }
    
    @staticmethod
    def extract_game_tokens(text: str) -> tuple:
        """
        Extrait les tokens de formatage du jeu et le texte √† traduire.
        Retourne un tuple (tokens, texte_clean).
        """
        tokens = []
        clean_text = text
        
        # Extraction des tokens de formatage du jeu
        for pattern, token_type in SpecialTokens.GAME_FORMAT_TOKENS.items():
            matches = re.finditer(pattern, text)
            for match in matches:
                token = match.group(0)
                # Stocke le token avec sa position et son type
                tokens.append({
                    'token': token,
                    'type': token_type,
                    'position': match.start(),
                    'length': len(token)
                })
                # Remplace le token par un espace pour pr√©server la longueur
                clean_text = clean_text[:match.start()] + ' ' * len(token) + clean_text[match.end():]
        
        # Nettoyage des espaces multiples tout en pr√©servant la structure
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        
        return tokens, clean_text
    
    @staticmethod
    def reconstruct_text(clean_text: str, tokens: list) -> str:
        """
        Reconstruit le texte original avec les tokens de formatage.
        Pr√©serve la structure et le formatage original.
        """
        # Trie les tokens par position d√©croissante pour ne pas perturber les indices
        sorted_tokens = sorted(tokens, key=lambda x: x['position'], reverse=True)
        
        result = clean_text
        for token_info in sorted_tokens:
            # Ins√®re le token √† sa position originale
            pos = token_info['position']
            result = result[:pos] + token_info['token'] + result[pos:]
        
        return result
    
    @staticmethod
    def is_special_token(text: str) -> bool:
        """V√©rifie si le texte contient des tokens sp√©ciaux."""
        # V√©rifie les tokens de formatage du jeu
        if any(re.search(pattern, text) for pattern in SpecialTokens.GAME_FORMAT_TOKENS.keys()):
            return True
            
        # V√©rifie les tokens de formatage standard
        if any(token in text for token in SpecialTokens.FORMAT_TOKENS):
            return True
            
        # V√©rifie les tokens de commande
        if any(text.startswith(token) for token in SpecialTokens.COMMAND_TOKENS):
            return True
            
        return False
    
    @staticmethod
    def preserve_special_tokens(original_text: str, translated_text: str) -> str:
        """Pr√©serve les tokens sp√©ciaux dans le texte traduit."""
        # Extraction des tokens du texte original
        tokens, clean_original = SpecialTokens.extract_game_tokens(original_text)
        
        # Si le texte original ne contient que des tokens sp√©ciaux
        if not clean_original.strip():
            return original_text
            
        # Nettoyage du texte traduit
        clean_translated = translated_text.strip()
        
        # Reconstruction du texte avec les tokens originaux
        return SpecialTokens.reconstruct_text(clean_translated, tokens)

class FileAnalyzer:
    """Analyseur automatique de fichiers pour d√©tecter le contenu traduisible."""
    
    def __init__(self):
        self.magic_signatures = {
            # Signatures de fichiers de jeu courants
            b'PM1\x00': 'pm1_format',
            b'PAC\x00': 'pac_format', 
            b'PAK\x00': 'pak_format',
            b'BF\x00\x00': 'bf_format',
            b'TBL\x00': 'tbl_format',
            
            # Signatures g√©n√©riques
            b'RIFF': 'riff_format',
            b'\x89PNG': 'png_image',
            b'MZ': 'executable',
            b'\x7fELF': 'elf_executable',
            
            # Archives
            b'PK\x03\x04': 'zip_archive',
            b'Rar!': 'rar_archive',
            
            # Formats de texte
            b'\xff\xfe': 'utf16_le_text',
            b'\xfe\xff': 'utf16_be_text',
            b'\xef\xbb\xbf': 'utf8_bom_text',
        }
        
        self.text_indicators = [
            # Mots courants en anglais dans les jeux
            br'[Ss]tart',
            br'[Pp]ress',
            br'[Gg]ame\s+[Oo]ver',
            br'[Ll]oading',
            br'[Cc]ontinue',
            br'[Nn]ew\s+[Gg]ame',
            br'[Ss]ave',
            br'[Ll]oad',
            br'[Qq]uit',
            br'[Ee]xit',
            br'[Oo]ptions',
            br'[Ss]ettings',
            br'[Vv]olume',
            br'[Hh]elp',
            br'[Yy]es',
            br'[Nn]o',
            br'[Oo][Kk]',
            br'[Cc]ancel',
            
            # Textes sp√©cifiques √† Persona
            br'[Pp]ersona',
            br'[Tt]artarus',
            br'SEES',
            br'[Ee]voker',
            br'[Ss]hadow',
            br'[Aa]rcana',
            br'[Cc]ompendium',
            br'[Vv]elvet\s+[Rr]oom',
        ]
        
        self.analysis_results = {}
    
    def detect_translation_status(self, file_path: Path) -> Dict:
        """
        D√©tecte si un fichier a d√©j√† √©t√© traduit et son niveau de traduction.
        Retourne des informations sur le statut de traduction.
        """
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
            
            if len(data) == 0:
                return {'status': 'empty', 'confidence': 0.0, 'indicators': []}
            
            # Convertir en texte pour analyse
            text_content = ""
            for encoding in ['utf-8', 'ascii', 'latin1', 'shift_jis']:
                try:
                    text_content = data.decode(encoding, errors='ignore')
                    break
                except:
                    continue
            
            # Indicateurs de traduction fran√ßaise
            french_indicators = [
                # Mots fran√ßais courants dans les jeux
                r'\b(?:bonjour|salut|bienvenue|merci|oui|non|annuler|continuer|quitter)\b',
                r'\b(?:jeu|partie|joueur|d√©marrer|charger|sauvegarder|options)\b',
                r'\b(?:nouveau|ancien|pr√©c√©dent|suivant|retour|aide|fin)\b',
                r'\b(?:appuyez|pressez|cliquez|s√©lectionnez|choisissez)\b',
                
                # Indicateurs sp√©cifiques aux traductions automatiques
                r'\b(?:chargement|chargeme|nouvea|annu|gibier|voit)\b',  # Textes tronqu√©s typiques
                r'\.\.\.+',  # Points de suspension multiples (troncature)
                
                # Accents et caract√®res fran√ßais
                r'[√†√¢√§√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ø√ß]',
                
                # Expressions fran√ßaises de jeu
                r'(?:fin de partie|game over traduit|partie termin√©e)',
                r'(?:essayer √† nouveau|r√©essayer)',
                r'(?:visitez|v√©rifiez|utilisez)',
            ]
            
            # Indicateurs anglais (pour d√©tecter les non-traduits)
            english_indicators = [
                r'\b(?:start|press|game\s+over|loading|new\s+game|continue|quit|yes|no|ok|cancel)\b',
                r'\b(?:welcome|hello|thanks|help|options|settings|save|load)\b',
                r'\b(?:try\s+again|game\s+over|press\s+any\s+key)\b',
            ]
            
            # Compter les occurrences
            french_count = 0
            english_count = 0
            translation_indicators = []
            
            text_lower = text_content.lower()
            
            for pattern in french_indicators:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                if matches:
                    french_count += len(matches)
                    translation_indicators.extend([f"French: {match}" for match in matches[:3]])  # Limiter les exemples
            
            for pattern in english_indicators:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                if matches:
                    english_count += len(matches)
            
            # Calculer le score de traduction
            total_indicators = french_count + english_count
            if total_indicators == 0:
                translation_ratio = 0.0
                status = 'no_text'
            else:
                translation_ratio = french_count / total_indicators
                if translation_ratio >= 0.7:
                    status = 'fully_translated'
                elif translation_ratio >= 0.3:
                    status = 'partially_translated'
                elif english_count > 0:
                    status = 'not_translated'
                else:
                    status = 'unknown'
            
            return {
                'status': status,
                'confidence': translation_ratio,
                'french_indicators': french_count,
                'english_indicators': english_count,
                'indicators': translation_indicators[:5],  # Top 5 exemples
                'total_indicators': total_indicators
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'confidence': 0.0,
                'indicators': [f"Error: {str(e)}"],
                'error': str(e)
            }
    
    def detect_file_format(self, file_path: Path) -> Tuple[str, float]:
        """
        D√©tecte le format d'un fichier et sa probabilit√© de contenir du texte.
        Retourne (format_detect√©, score_de_confiance)
        """
        try:
            with open(file_path, 'rb') as f:
                header = f.read(512)  # Lire les premiers 512 bytes
                
            if not header:
                return 'empty_file', 0.0
            
            # V√©rification des signatures magiques
            detected_format = 'unknown'
            for signature, format_name in self.magic_signatures.items():
                if header.startswith(signature):
                    detected_format = format_name
                    break
            
            # Score bas√© sur la pr√©sence de texte lisible
            text_score = self._calculate_text_score(header)
            
            # Bonus pour les formats de jeu connus
            format_bonus = 0.0
            if detected_format in ['pm1_format', 'pac_format', 'pak_format', 'bf_format', 'tbl_format']:
                format_bonus = 0.3
            elif 'text' in detected_format:
                format_bonus = 0.5
            
            final_score = min(1.0, text_score + format_bonus)
            
            return detected_format, final_score
            
        except Exception as e:
            logging.debug(f"Erreur d'analyse de {file_path}: {e}")
            return 'error', 0.0
    
    def _calculate_text_score(self, data: bytes) -> float:
        """Calcule un score de probabilit√© de pr√©sence de texte."""
        if len(data) == 0:
            return 0.0
        
        # Compteur de caract√®res imprimables
        printable_count = 0
        for byte in data:
            if 32 <= byte <= 126 or byte in [9, 10, 13]:  # ASCII imprimable + TAB/LF/CR
                printable_count += 1
        
        printable_ratio = printable_count / len(data)
        
        # Recherche de mots indicateurs
        indicator_score = 0.0
        for pattern in self.text_indicators:
            if re.search(pattern, data, re.IGNORECASE):
                indicator_score += 0.1
        
        # Score final
        text_score = (printable_ratio * 0.7) + min(indicator_score, 0.3)
        
        return text_score
    
    def analyze_directory(self, directory: Path, max_files: int = None) -> Dict:
        """
        Analyse tous les fichiers d'un r√©pertoire et retourne un rapport.
        """
        analysis_report = {
            'total_files': 0,
            'analyzed_files': 0,
            'promising_files': [],
            'translated_files': [],
            'untranslated_files': [],
            'partially_translated_files': [],
            'by_format': defaultdict(list),
            'by_score': defaultdict(list),
            'by_translation_status': defaultdict(list),
            'errors': [],
            'recommendations': [],
            'translation_summary': {
                'fully_translated': 0,
                'partially_translated': 0,
                'not_translated': 0,
                'no_text': 0,
                'unknown': 0,
                'error': 0
            },
            'ignored_files': 0
        }
        
        all_files = []
        ignored_count = 0
        
        for root, _, files in os.walk(directory):
            for file in files:
                file_path = Path(root) / file
                if file_path.is_file():
                    # Ignorer les fichiers .backup
                    if file_path.suffix.lower() == '.backup' or '.backup' in file_path.name:
                        ignored_count += 1
                        continue
                    all_files.append(file_path)
        
        analysis_report['total_files'] = len(all_files)
        analysis_report['ignored_files'] = ignored_count
        
        # Limiter si demand√©
        if max_files and len(all_files) > max_files:
            all_files = all_files[:max_files]
            analysis_report['note'] = f"Analyse limit√©e aux {max_files} premiers fichiers"
        
        for file_path in all_files:
            try:
                file_format, score = self.detect_file_format(file_path)
                translation_status = self.detect_translation_status(file_path)
                
                file_info = {
                    'path': str(file_path),
                    'name': file_path.name,
                    'size': file_path.stat().st_size,
                    'format': file_format,
                    'text_score': score,
                    'extension': file_path.suffix.lower(),
                    'translation_status': translation_status['status'],
                    'translation_confidence': translation_status['confidence'],
                    'french_indicators': translation_status.get('french_indicators', 0),
                    'english_indicators': translation_status.get('english_indicators', 0),
                    'translation_examples': translation_status.get('indicators', [])
                }
                
                analysis_report['by_format'][file_format].append(file_info)
                analysis_report['analyzed_files'] += 1
                
                # Classer par statut de traduction
                status = translation_status['status']
                analysis_report['by_translation_status'][status].append(file_info)
                analysis_report['translation_summary'][status] += 1
                
                # Classer par score
                if score >= 0.7:
                    analysis_report['by_score']['high'].append(file_info)
                    # Ne consid√©rer comme prometteur que s'il n'est pas d√©j√† traduit
                    if status not in ['fully_translated']:
                        analysis_report['promising_files'].append(file_info)
                        analysis_report['untranslated_files'].append(file_info)
                    elif status == 'fully_translated':
                        analysis_report['translated_files'].append(file_info)
                elif score >= 0.4:
                    analysis_report['by_score']['medium'].append(file_info)
                    if status not in ['fully_translated']:
                        analysis_report['promising_files'].append(file_info)
                        analysis_report['untranslated_files'].append(file_info)
                    elif status == 'fully_translated':
                        analysis_report['translated_files'].append(file_info)
                elif score >= 0.1:
                    analysis_report['by_score']['low'].append(file_info)
                else:
                    analysis_report['by_score']['none'].append(file_info)
                
                # Fichiers partiellement traduits
                if status == 'partially_translated':
                    analysis_report['partially_translated_files'].append(file_info)
                    
            except Exception as e:
                error_info = {
                    'file': str(file_path),
                    'error': str(e)
                }
                analysis_report['errors'].append(error_info)
        
        # G√©n√©rer des recommandations
        analysis_report['recommendations'] = self._generate_recommendations_with_translation(analysis_report)
        
        return analysis_report
    
    def _generate_recommendations(self, report: Dict) -> List[str]:
        """G√©n√®re des recommandations bas√©es sur l'analyse."""
        recommendations = []
        
        high_score_count = len(report['by_score']['high'])
        medium_score_count = len(report['by_score']['medium'])
        
        if high_score_count > 0:
            recommendations.append(f"üéØ {high_score_count} fichier(s) tr√®s prometteur(s) d√©tect√©(s)")
            recommendations.append("üí° Commencez par traiter les fichiers avec un score √©lev√©")
        
        if medium_score_count > 0:
            recommendations.append(f"üîç {medium_score_count} fichier(s) moyennement prometteur(s)")
            recommendations.append("üí° Testez ces fichiers en mode test avant traduction compl√®te")
        
        # Recommandations par format
        for format_name, files in report['by_format'].items():
            if format_name in ['pm1_format', 'pac_format', 'pak_format'] and len(files) > 0:
                recommendations.append(f"üéÆ {len(files)} fichier(s) au format {format_name} d√©tect√©(s)")
                recommendations.append("üí° Ces formats sont typiques des jeux et m√©ritent une attention particuli√®re")
        
        if len(report['errors']) > 0:
            recommendations.append(f"‚ö†Ô∏è {len(report['errors'])} fichier(s) n'ont pas pu √™tre analys√©s")
        
        return recommendations
    
    def _generate_recommendations_with_translation(self, report: Dict) -> List[str]:
        """G√©n√®re des recommandations bas√©es sur l'analyse incluant le statut de traduction."""
        recommendations = []
        
        # Statistiques de traduction
        total_files = report['analyzed_files']
        translated_count = report['translation_summary']['fully_translated']
        untranslated_count = len(report['untranslated_files'])
        partially_translated_count = report['translation_summary']['partially_translated']
        
        # Calcul du progr√®s
        if total_files > 0:
            progress_percent = (translated_count / total_files) * 100
            recommendations.append(f"üìä Progr√®s de traduction: {progress_percent:.1f}% ({translated_count}/{total_files} fichiers)")
        
        # Recommandations bas√©es sur le progr√®s
        if untranslated_count > 0:
            recommendations.append(f"üéØ {untranslated_count} fichier(s) restant(s) √† traduire")
            recommendations.append("üí° Utilisez --auto pour traiter automatiquement les fichiers non traduits")
            
            if untranslated_count <= 5:
                recommendations.append("üèÅ Vous √™tes proche de la fin ! Quelques fichiers seulement")
            elif untranslated_count <= 20:
                recommendations.append("‚ö° Bon progr√®s ! Environ 20 fichiers ou moins √† traiter")
            else:
                recommendations.append("üöÄ Beaucoup de fichiers √† traiter, le mode automatique est recommand√©")
        else:
            recommendations.append("üéâ Tous les fichiers prometteurs semblent d√©j√† traduits !")
        
        if partially_translated_count > 0:
            recommendations.append(f"‚ö†Ô∏è {partially_translated_count} fichier(s) partiellement traduit(s)")
            recommendations.append("üí° Ces fichiers peuvent n√©cessiter une re-traduction")
        
        if translated_count > 0:
            recommendations.append(f"‚úÖ {translated_count} fichier(s) d√©j√† traduit(s) (ignor√©s automatiquement)")
        
        # Recommandations par format (inchang√©es)
        for format_name, files in report['by_format'].items():
            if format_name in ['pm1_format', 'pac_format', 'pak_format'] and len(files) > 0:
                untranslated_in_format = [f for f in files if f.get('translation_status') not in ['fully_translated']]
                if untranslated_in_format:
                    recommendations.append(f"üéÆ {len(untranslated_in_format)}/{len(files)} fichier(s) {format_name} √† traduire")
        
        if len(report['errors']) > 0:
            recommendations.append(f"‚ö†Ô∏è {len(report['errors'])} fichier(s) n'ont pas pu √™tre analys√©s")
        
        # Recommandations sp√©cifiques selon la situation
        if untranslated_count == 0 and translated_count > 0:
            recommendations.append("üéä Traduction compl√®te ! Vous pouvez relancer l'analyse pour v√©rifier")
        elif untranslated_count > 0 and translated_count > 0:
            recommendations.append("üîÑ Reprise de traduction d√©tect√©e - progression sauvegard√©e")
        
        return recommendations

class AdaptiveReinsertionManager:
    """Gestionnaire de m√©thodes de r√©insertion adaptatives selon le type de fichier."""
    
    def __init__(self):
        self.reinsertion_strategies = {
            'pm1_format': 'conservative',
            'pac_format': 'aggressive', 
            'pak_format': 'conservative',
            'bf_format': 'safe',
            'tbl_format': 'direct',
            'unknown': 'test_first',
            'text_file': 'direct'
        }
        
        self.test_results = {}
    
    def choose_strategy(self, file_format: str, file_path: Path, test_mode: bool = False) -> str:
        """
        Choisit la strat√©gie de r√©insertion optimale pour un fichier.
        """
        base_strategy = self.reinsertion_strategies.get(file_format, 'test_first')
        
        # Si on a des r√©sultats de test pour ce fichier
        if str(file_path) in self.test_results:
            test_result = self.test_results[str(file_path)]
            if test_result['success']:
                return test_result['best_strategy']
            else:
                return 'safe'  # Fallback s√©curis√©
        
        # Si mode test activ√©, toujours tester d'abord
        if test_mode:
            return 'test_first'
            
        return base_strategy
    
    def test_reinsertion_methods(self, file_path: Path, translator) -> Dict:
        """
        Teste diff√©rentes m√©thodes de r√©insertion sur un fichier et retourne les r√©sultats.
        """
        test_results = {
            'file': str(file_path),
            'methods_tested': [],
            'success': False,
            'best_strategy': 'safe',
            'details': {}
        }
        
        try:
            # Extraction pour avoir des donn√©es de test
            original_texts = translator.extract_texts(file_path)
            if not original_texts:
                test_results['details']['extraction'] = 'failed'
                return test_results
            
            test_results['details']['extraction'] = f'{len(original_texts)} texts extracted'
            
            # Cr√©er des traductions de test (courtes pour minimiser les probl√®mes)
            test_translations = []
            for text in original_texts:
                if len(text) <= 5:
                    test_translations.append(text)  # Garder les textes tr√®s courts
                elif len(text) <= 15:
                    test_translations.append(text[:len(text)-2] + ".")  # Raccourcir l√©g√®rement
                else:
                    test_translations.append(text[:len(text)//2] + "...")  # Raccourcir significativement
            
            # Tester diff√©rentes strat√©gies
            strategies_to_test = ['conservative', 'safe', 'aggressive']
            best_score = 0
            best_strategy = 'safe'
            
            for strategy in strategies_to_test:
                strategy_result = self._test_strategy(file_path, test_translations, translator, strategy)
                test_results['methods_tested'].append(strategy)
                test_results['details'][strategy] = strategy_result
                
                if strategy_result['success'] and strategy_result['score'] > best_score:
                    best_score = strategy_result['score']
                    best_strategy = strategy
                    test_results['success'] = True
            
            test_results['best_strategy'] = best_strategy
            
        except Exception as e:
            test_results['details']['error'] = str(e)
            
        return test_results
    
    def _test_strategy(self, file_path: Path, test_translations: List[str], translator, strategy: str) -> Dict:
        """Teste une strat√©gie sp√©cifique de r√©insertion."""
        result = {
            'success': False,
            'score': 0,
            'details': ''
        }
        
        # Cr√©er un fichier de test
        test_file = file_path.with_suffix(f'.test_{strategy}{file_path.suffix}')
        
        try:
            shutil.copy2(file_path, test_file)
            
            # Effectuer l'extraction sur le fichier de test d'abord
            # pour cr√©er le fichier JSON n√©cessaire
            extracted_texts = translator.extract_texts(test_file)
            if not extracted_texts:
                result['details'] = 'Extraction failed'
                return result
            
            # Sauvegarder la m√©thode actuelle
            original_method = getattr(translator, '_current_reinsertion_mode', 'default')
            
            # Appliquer la strat√©gie
            translator._current_reinsertion_mode = strategy
            
            # Tenter la r√©insertion
            success = translator.reinsert_texts(test_file, test_translations)
            
            if success:
                # V√©rifier l'int√©grit√© en extrayant √† nouveau
                new_texts = translator.extract_texts(test_file)
                
                if new_texts and len(new_texts) == len(test_translations):
                    # Calculer un score bas√© sur les changements d√©tect√©s
                    changes_detected = sum(1 for old, new in zip(test_translations, new_texts) if old != new)
                    integrity_score = len(new_texts) / len(test_translations)
                    change_score = min(1.0, changes_detected / len(test_translations))
                    
                    result['score'] = (integrity_score * 0.7) + (change_score * 0.3)
                    result['success'] = True
                    result['details'] = f'Changes: {changes_detected}/{len(test_translations)}, Integrity: {integrity_score:.2f}'
                else:
                    result['details'] = 'Integrity check failed'
            else:
                result['details'] = 'Reinsertion failed'
            
            # Restaurer la m√©thode originale
            translator._current_reinsertion_mode = original_method
            
        except Exception as e:
            result['details'] = f'Exception: {str(e)}'
        finally:
            # Nettoyage
            if test_file.exists():
                test_file.unlink()
        
        return result
    
    def apply_strategy(self, strategy: str, translator, file_path: Path, translations: List[str]) -> bool:
        """Applique une strat√©gie sp√©cifique de r√©insertion."""
        
        if strategy == 'conservative':
            return self._conservative_reinsertion(translator, file_path, translations)
        elif strategy == 'aggressive':
            return self._aggressive_reinsertion(translator, file_path, translations)
        elif strategy == 'safe':
            return self._safe_reinsertion(translator, file_path, translations)
        elif strategy == 'direct':
            return translator.reinsert_texts(file_path, translations)
        else:
            # Fallback vers la m√©thode standard
            return translator.reinsert_texts(file_path, translations)
    
    def _conservative_reinsertion(self, translator, file_path: Path, translations: List[str]) -> bool:
        """M√©thode conservative: utilise maintenant aussi le mode sans limitation."""
        # Nouvelle approche: m√™me en mode conservateur, on accepte les textes longs
        # mais on log plus d'informations pour le suivi
        logging.info(f"Mode conservateur avec r√©int√©gration compl√®te pour {file_path.name}")
        return translator.reinsert_texts(file_path, translations)
    
    def _aggressive_reinsertion(self, translator, file_path: Path, translations: List[str]) -> bool:
        """M√©thode agressive: r√©int√©gration compl√®te avec expansion de fichier si n√©cessaire."""
        # Mode agressif: accepter TOUS les textes et √©tendre le fichier si n√©cessaire
        logging.info(f"Mode agressif avec expansion automatique pour {file_path.name}")
        return translator.reinsert_texts(file_path, translations)
    
    def _safe_reinsertion(self, translator, file_path: Path, translations: List[str]) -> bool:
        """M√©thode s√ªre: cr√©e une sauvegarde et teste avant application finale."""
        # Cr√©er une sauvegarde suppl√©mentaire
        backup_file = file_path.with_suffix(file_path.suffix + f'.safe_backup_{int(time.time())}')
        shutil.copy2(file_path, backup_file)
        
        try:
            # Tenter la r√©insertion
            success = translator.reinsert_texts(file_path, translations)
            
            if success:
                # V√©rification post-r√©insertion
                new_texts = translator.extract_texts(file_path)
                if new_texts and len(new_texts) >= len(translations) * 0.8:  # Au moins 80% des textes
                    logging.info(f"R√©insertion s√ªre r√©ussie pour {file_path}")
                    return True
                else:
                    # Restaurer depuis la sauvegarde
                    shutil.copy2(backup_file, file_path)
                    logging.warning(f"R√©insertion √©chou√©e, fichier restaur√© pour {file_path}")
                    return False
            else:
                return False
                
        except Exception as e:
            # Restaurer depuis la sauvegarde en cas d'erreur
            if backup_file.exists():
                shutil.copy2(backup_file, file_path)
            logging.error(f"Erreur lors de la r√©insertion s√ªre: {e}")
            return False
        finally:
            # Nettoyage de la sauvegarde temporaire
            if backup_file.exists():
                backup_file.unlink()

class TranslationCache:
    """Cache SQLite intelligent pour les traductions avec TTL."""
    
    def __init__(self, cache_dir: Path, ttl_hours: int = 24*7):
        self.cache_file = cache_dir / "translation_cache.db"
        self.ttl = timedelta(hours=ttl_hours)
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self._init_db()
        self._lock = threading.Lock()
    
    def _init_db(self):
        """Initialise la base de donn√©es SQLite."""
        with sqlite3.connect(self.cache_file) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS translations (
                    text_hash TEXT PRIMARY KEY,
                    original_text TEXT NOT NULL,
                    translated_text TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    accessed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    access_count INTEGER DEFAULT 1
                )
            ''')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_created_at ON translations(created_at)')
    
    def get(self, text: str) -> Optional[str]:
        """R√©cup√®re une traduction du cache."""
        text_hash = hashlib.sha256(text.encode('utf-8')).hexdigest()
        
        with self._lock:
            with sqlite3.connect(self.cache_file) as conn:
                cursor = conn.execute(
                    'SELECT translated_text, created_at FROM translations WHERE text_hash = ?',
                    (text_hash,)
                )
                row = cursor.fetchone()
                
                if row:
                    created_at = datetime.fromisoformat(row[1])
                    if datetime.now() - created_at < self.ttl:
                        # Mettre √† jour les stats d'acc√®s
                        conn.execute(
                            'UPDATE translations SET accessed_at = ?, access_count = access_count + 1 WHERE text_hash = ?',
                            (datetime.now().isoformat(), text_hash)
                        )
                        return row[0]
                    else:
                        # Supprimer l'entr√©e expir√©e
                        conn.execute('DELETE FROM translations WHERE text_hash = ?', (text_hash,))
        return None
    
    def put(self, text: str, translation: str):
        """Stocke une traduction dans le cache."""
        text_hash = hashlib.sha256(text.encode('utf-8')).hexdigest()
        now = datetime.now().isoformat()
        
        with self._lock:
            with sqlite3.connect(self.cache_file) as conn:
                conn.execute('''
                    INSERT OR REPLACE INTO translations 
                    (text_hash, original_text, translated_text, created_at, accessed_at, access_count)
                    VALUES (?, ?, ?, ?, ?, 1)
                ''', (text_hash, text, translation, now, now))
    
    def cleanup_expired(self) -> int:
        """Nettoie les entr√©es expir√©es."""
        cutoff = datetime.now() - self.ttl
        with self._lock:
            with sqlite3.connect(self.cache_file) as conn:
                cursor = conn.execute(
                    'DELETE FROM translations WHERE datetime(created_at) < ?',
                    (cutoff.isoformat(),)
                )
                return cursor.rowcount
    
    def get_stats(self) -> Dict:
        """Retourne les statistiques du cache."""
        with self._lock:
            with sqlite3.connect(self.cache_file) as conn:
                cursor = conn.execute('''
                    SELECT COUNT(*) as total,
                           SUM(access_count) as total_hits,
                           COUNT(CASE WHEN datetime(created_at) > datetime('now', '-24 hours') THEN 1 END) as recent
                    FROM translations
                ''')
                row = cursor.fetchone()
                return {
                    'total_entries': row[0] or 0,
                    'total_hits': row[1] or 0,
                    'recent_entries': row[2] or 0
                }

class EnhancedTranslationService:
    """Service de traduction am√©lior√© avec retry, cache et fallback."""
    
    def __init__(self, cache_dir: Path):
        self.cache = TranslationCache(cache_dir)
        self.translator = GoogleTranslator(source='en', target='fr')
        self.stats = {
            'translations_requested': 0,
            'cache_hits': 0,
            'translation_errors': 0,
            'successful_translations': 0
        }
        self._session = requests.Session()
        # Configuration retry pour requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self._session.mount("http://", adapter)
        self._session.mount("https://", adapter)
    
    def translate_with_retry(self, text: str, max_retries: int = 3) -> str:
        """Traduit un texte avec retry automatique."""
        self.stats['translations_requested'] += 1
        
        # V√©rifier le cache d'abord
        cached = self.cache.get(text)
        if cached:
            self.stats['cache_hits'] += 1
            return cached
        
        # Essayer la traduction avec retry
        for attempt in range(max_retries):
            try:
                translated = self.translator.translate(text)
                if translated and translated.strip():
                    # Succ√®s - sauvegarder dans le cache
                    self.cache.put(text, translated)
                    self.stats['successful_translations'] += 1
                    return translated
            except Exception as e:
                logging.warning(f"Tentative {attempt + 1}/{max_retries} √©chou√©e: {e}")
                if attempt < max_retries - 1:
                    time.sleep(min(2 ** attempt, 10))  # Backoff exponentiel
        
        # Toutes les tentatives ont √©chou√©
        self.stats['translation_errors'] += 1
        logging.error(f"√âchec complet de traduction pour '{text[:50]}...'")
        return text  # Retourner le texte original
    
    def translate_batch(self, texts: List[str], max_workers: int = 3) -> List[str]:
        """Traduit un lot de textes en parall√®le."""
        if not texts:
            return []
        
        results = [None] * len(texts)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Soumettre toutes les t√¢ches
            future_to_index = {
                executor.submit(self.translate_with_retry, text): i
                for i, text in enumerate(texts)
            }
            
            # Collecter les r√©sultats dans l'ordre
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    results[index] = future.result()
                except Exception as e:
                    logging.error(f"Erreur traduction batch index {index}: {e}")
                    results[index] = texts[index]  # Fallback au texte original
        
        return results
    
    def get_cache_stats(self) -> Dict:
        """Retourne les statistiques combin√©es."""
        cache_stats = self.cache.get_stats()
        hit_rate = (self.stats['cache_hits'] / max(self.stats['translations_requested'], 1)) * 100
        
        return {
            'service_stats': self.stats,
            'cache_stats': cache_stats,
            'cache_hit_rate': round(hit_rate, 1)
        }
    
    def cleanup_cache(self) -> int:
        """Nettoie le cache expir√©."""
        return self.cache.cleanup_expired()

class P3FESTranslator:
    def __init__(self, game_dir: str, output_dir: str):
        """
        Initialise le traducteur pour Persona 3 FES.
        
        Args:
            game_dir (str): Chemin vers le r√©pertoire du jeu
            output_dir (str): Chemin vers le r√©pertoire de sortie pour les fichiers traduits
        """
        self.game_dir = Path(game_dir)
        self.output_dir = Path(output_dir)
        self.processed_files = self._load_processed_files()
        self.supported_extensions = {'.pm1', '.pac', '.pak', '.bf', '.tbl'}
        
        # Nouveaux composants pour l'analyse automatique
        self.file_analyzer = FileAnalyzer()
        self.reinsertion_manager = AdaptiveReinsertionManager()
        self.analysis_report = None
        self._current_reinsertion_mode = 'default'
        
        # Cr√©ation des r√©pertoires n√©cessaires
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / 'extracted').mkdir(exist_ok=True)
        (self.output_dir / 'translated').mkdir(exist_ok=True)
        (self.output_dir / 'analysis').mkdir(exist_ok=True)
        (self.output_dir / 'cache').mkdir(exist_ok=True)
        
        self.special_tokens = SpecialTokens()
        
        # Service de traduction am√©lior√© avec cache et retry
        self.translation_service = EnhancedTranslationService(self.output_dir / 'cache')
        
        # Patterns regex pr√©-compil√©s pour l'optimisation
        self._compiled_patterns = self._compile_extraction_patterns()
        
        # Initialisation du mod√®le Hugging Face pour l'analyse de texte
        try:
            self.text_classifier = pipeline(
                "text-classification",
                model="cardiffnlp/twitter-roberta-base-sentiment-latest",
                device=-1  # CPU
            )
            logging.info("Mod√®le Hugging Face charg√© avec succ√®s")
        except Exception as e:
            logging.warning(f"Mod√®le Hugging Face non disponible: {e}")
            logging.info("Continuera sans analyse de sentiment avanc√©e")
            self.text_classifier = None
    
    def _compile_extraction_patterns(self) -> List[re.Pattern]:
        """Compile les patterns regex pour l'extraction pour optimiser les performances."""
        patterns = [
            rb'[\x20-\x7E\x80-\xFF]{8,}',  # Cha√Ænes ASCII √©tendues
            rb'[\x20-\x7E]{4,}',           # Cha√Ænes ASCII standard
        ]
        return [re.compile(pattern) for pattern in patterns]

    def _load_processed_files(self) -> Dict[str, str]:
        """Charge la liste des fichiers d√©j√† trait√©s depuis le fichier log."""
        log_file = self.output_dir / 'processed_files.json'
        if log_file.exists():
            with open(log_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _save_processed_files(self):
        """Sauvegarde la liste des fichiers trait√©s dans le fichier log."""
        log_file = self.output_dir / 'processed_files.json'
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(self.processed_files, f, indent=4, ensure_ascii=False)
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """Calcule le hash SHA-256 d'un fichier."""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    
    def _is_file_modified(self, file_path: Path) -> bool:
        """V√©rifie si un fichier a √©t√© modifi√© depuis son dernier traitement."""
        if str(file_path) not in self.processed_files:
            return True
        current_hash = self._calculate_file_hash(file_path)
        return current_hash != self.processed_files[str(file_path)]
    
    def analyze_all_files(self, max_files: int = None) -> Dict:
        """
        Analyse tous les fichiers du r√©pertoire de jeu pour d√©tecter le contenu traduisible.
        """
        logging.info("üîç D√©but de l'analyse automatique des fichiers...")
        
        # Utiliser l'analyseur de fichiers
        analysis_report = self.file_analyzer.analyze_directory(self.game_dir, max_files)
        self.analysis_report = analysis_report
        
        # Sauvegarder le rapport d'analyse
        report_file = self.output_dir / 'analysis' / 'file_analysis_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_report, f, indent=2, ensure_ascii=False)
        
        logging.info(f"üìä Rapport d'analyse sauvegard√© dans {report_file}")
        
        return analysis_report
    
    def print_analysis_summary(self):
        """Affiche un r√©sum√© de l'analyse des fichiers incluant le statut de traduction."""
        if not self.analysis_report:
            print("‚ùå Aucune analyse disponible. Ex√©cutez analyze_all_files() d'abord.")
            return
        
        report = self.analysis_report
        
        print("\nüìä RAPPORT D'ANALYSE INTELLIGENT DES FICHIERS")
        print("=" * 50)
        print(f"üìÅ Fichiers analys√©s: {report['analyzed_files']}/{report['total_files']}")
        
        if report.get('ignored_files', 0) > 0:
            print(f"üö´ Fichiers .backup ignor√©s: {report['ignored_files']}")
        
        # Statistiques de traduction
        summary = report['translation_summary']
        total_with_text = sum(summary.values()) - summary['no_text'] - summary['error']
        
        if total_with_text > 0:
            print(f"\nüîÑ STATUT DE TRADUCTION:")
            if summary['fully_translated'] > 0:
                print(f"  ‚úÖ Traduits: {summary['fully_translated']} fichier(s)")
            if summary['partially_translated'] > 0:
                print(f"  üî∂ Partiellement traduits: {summary['partially_translated']} fichier(s)")
            if summary['not_translated'] > 0:
                print(f"  ‚ùå Non traduits: {summary['not_translated']} fichier(s)")
            if summary['unknown'] > 0:
                print(f"  ‚ùì Statut inconnu: {summary['unknown']} fichier(s)")
            
            # Calcul et affichage du progr√®s
            translated_count = summary['fully_translated']
            progress_percent = (translated_count / total_with_text) * 100
            progress_bar = "‚ñà" * int(progress_percent // 5) + "‚ñë" * (20 - int(progress_percent // 5))
            print(f"  üìà Progr√®s: [{progress_bar}] {progress_percent:.1f}%")
        
        print(f"\nüéØ Fichiers √† traiter: {len(report['untranslated_files'])}")
        if len(report['translated_files']) > 0:
            print(f"‚úÖ Fichiers d√©j√† traduits: {len(report['translated_files'])} (ignor√©s)")
        
        print("\nüìã R√©partition par format:")
        for format_name, files in report['by_format'].items():
            if files:
                # Compter les non-traduits par format
                untranslated_in_format = [f for f in files if f.get('translation_status') not in ['fully_translated']]
                translated_in_format = [f for f in files if f.get('translation_status') == 'fully_translated']
                
                status_info = ""
                if translated_in_format and untranslated_in_format:
                    status_info = f" ({len(untranslated_in_format)} √† faire, {len(translated_in_format)} faits)"
                elif translated_in_format:
                    status_info = f" (tous traduits)"
                elif untranslated_in_format:
                    status_info = f" (√† traduire)"
                
                print(f"  ‚Ä¢ {format_name}: {len(files)} fichier(s){status_info}")
        
        print("\nüìà R√©partition par score de confiance:")
        for score_level, files in report['by_score'].items():
            if files:
                level_names = {
                    'high': '√âlev√© (‚â•70%)',
                    'medium': 'Moyen (40-70%)',
                    'low': 'Faible (10-40%)',
                    'none': 'Tr√®s faible (<10%)'
                }
                print(f"  ‚Ä¢ {level_names.get(score_level, score_level)}: {len(files)} fichier(s)")
        
        if report['errors']:
            print(f"\n‚ö†Ô∏è Erreurs d'analyse: {len(report['errors'])}")
        
        print("\nüí° RECOMMANDATIONS:")
        for recommendation in report['recommendations']:
            print(f"  {recommendation}")
        
        # Affichage des exemples de fichiers partiellement traduits
        if report['partially_translated_files']:
            print(f"\nüîç FICHIERS PARTIELLEMENT TRADUITS:")
            for file_info in report['partially_translated_files'][:3]:  # Top 3
                examples = file_info.get('translation_examples', [])
                examples_text = ", ".join(examples[:2]) if examples else "Aucun exemple"
                print(f"  üìÑ {file_info['name']} - Confiance: {file_info['translation_confidence']:.1%}")
                print(f"      Exemples: {examples_text}")
        
        # Affichage des prochains fichiers √† traiter
        if len(report['untranslated_files']) > 0:
            print(f"\nüìã PROCHAINS FICHIERS √Ä TRAITER:")
            for file_info in sorted(report['untranslated_files'], key=lambda x: x['text_score'], reverse=True)[:5]:
                score = file_info['text_score']
                format_name = file_info['format']
                print(f"  üìÑ {file_info['name']} - Score: {score:.1%} ({format_name})")
        
        if len(report['untranslated_files']) == 0 and len(report['translated_files']) > 0:
            print(f"\nüéâ F√âLICITATIONS ! Tous les fichiers prometteurs sont traduits !")
            print(f"   Vous pouvez relancer l'analyse pour v√©rifier ou affiner les param√®tres.")
    
    def get_promising_files(self, min_score: float = 0.3, exclude_translated: bool = True) -> List[Path]:
        """
        Retourne la liste des fichiers prometteurs pour la traduction.
        
        Args:
            min_score: Score minimum pour consid√©rer un fichier comme prometteur
            exclude_translated: Si True, exclut les fichiers d√©j√† traduits
        """
        if not self.analysis_report:
            # Analyser d'abord si pas encore fait
            self.analyze_all_files()
        
        promising_files = []
        
        if exclude_translated:
            # Utiliser la liste des fichiers non traduits
            for file_info in self.analysis_report['untranslated_files']:
                if file_info['text_score'] >= min_score:
                    promising_files.append(Path(file_info['path']))
        else:
            # Utiliser l'ancienne m√©thode (tous les fichiers prometteurs)
            for file_info in self.analysis_report['promising_files']:
                if file_info['text_score'] >= min_score:
                    promising_files.append(Path(file_info['path']))
        
        return promising_files
    
    def auto_process_directory(self, test_mode: bool = True, min_score: float = 0.4):
        """
        Traite automatiquement tous les fichiers prometteurs du r√©pertoire avec parall√©lisation.
        
        Args:
            test_mode: Si True, teste les m√©thodes de r√©insertion avant application
            min_score: Score minimum pour consid√©rer un fichier comme prometteur
        """
        logging.info("üöÄ D√©but du traitement automatique optimis√©...")
        
        # Analyser tous les fichiers
        if not self.analysis_report:
            self.analyze_all_files()
        
        # Obtenir les fichiers prometteurs
        promising_files = self.get_promising_files(min_score)
        
        if not promising_files:
            print("‚ùå Aucun fichier prometteur d√©tect√©.")
            return
        
        print(f"üìÅ {len(promising_files)} fichier(s) s√©lectionn√©(s) pour traitement")
        
        # Nettoyage du cache avant le d√©but
        expired_count = self.translation_service.cleanup_cache()
        if expired_count > 0:
            print(f"üßπ {expired_count} entr√©e(s) expir√©e(s) supprim√©e(s) du cache")
        
        # Statistiques
        processed_count = 0
        error_count = 0
        test_results = {}
        
        # Mode parall√©lis√© pour les gros volumes
        if len(promising_files) > 5:
            print("‚ö° Mode parall√©lis√© activ√© pour optimiser les performances")
            
            def process_single_file(file_path):
                """Fonction worker pour le traitement parall√®le."""
                try:
                    file_format, confidence = self.file_analyzer.detect_file_format(file_path)
                    
                    if test_mode:
                        test_result = self.reinsertion_manager.test_reinsertion_methods(file_path, self)
                        if not test_result['success']:
                            return False, f"Aucune m√©thode de r√©insertion trouv√©e"
                    
                    strategy = self.reinsertion_manager.choose_strategy(file_format, file_path, test_mode)
                    success = self.process_file_with_strategy(file_path, strategy)
                    
                    return success, "Succ√®s" if success else "√âchec"
                    
                except Exception as e:
                    return False, str(e)
            
            # Traitement parall√®le avec ThreadPoolExecutor
            with ThreadPoolExecutor(max_workers=2) as executor:  # Limiter √† 2 workers pour √©viter la saturation API
                future_to_file = {
                    executor.submit(process_single_file, file_path): file_path
                    for file_path in promising_files
                }
                
                for i, future in enumerate(as_completed(future_to_file), 1):
                    file_path = future_to_file[future]
                    print(f"\nüìÑ [{i}/{len(promising_files)}] {file_path.name}")
                    
                    try:
                        success, message = future.result()
                        if success:
                            processed_count += 1
                            print(f"  ‚úÖ {message}")
                        else:
                            error_count += 1
                            print(f"  ‚ùå {message}")
                    except Exception as e:
                        error_count += 1
                        print(f"  ‚ùå Erreur: {e}")
        else:
            # Mode s√©quentiel pour les petits volumes
            for i, file_path in enumerate(promising_files, 1):
                print(f"\nüìÑ [{i}/{len(promising_files)}] Traitement: {file_path.name}")
                
                try:
                    # D√©tecter le format pour choisir la strat√©gie
                    file_format, confidence = self.file_analyzer.detect_file_format(file_path)
                    print(f"  üîç Format d√©tect√©: {file_format} (confiance: {confidence:.1%})")
                    
                    # Si mode test activ√©, tester les m√©thodes de r√©insertion
                    if test_mode:
                        print(f"  üß™ Test des m√©thodes de r√©insertion...")
                        test_result = self.reinsertion_manager.test_reinsertion_methods(file_path, self)
                        test_results[str(file_path)] = test_result
                        
                        if not test_result['success']:
                            print(f"  ‚ö†Ô∏è Aucune m√©thode de r√©insertion fonctionnelle trouv√©e")
                            error_count += 1
                            continue
                        
                        print(f"  ‚úÖ Meilleure strat√©gie: {test_result['best_strategy']}")
                    
                    # Traitement avec la strat√©gie adapt√©e
                    strategy = self.reinsertion_manager.choose_strategy(file_format, file_path, test_mode)
                    print(f"  üîß Strat√©gie utilis√©e: {strategy}")
                    
                    if self.process_file_with_strategy(file_path, strategy):
                        processed_count += 1
                        print(f"  ‚úÖ Succ√®s")
                    else:
                        error_count += 1
                        print(f"  ‚ùå √âchec")
                        
                except Exception as e:
                    error_count += 1
                    print(f"  ‚ùå Erreur: {e}")
                    logging.error(f"Erreur lors du traitement de {file_path}: {e}")
        
        # Rapport final avec statistiques du cache
        print(f"\nüìà R√âSUM√â DU TRAITEMENT AUTOMATIQUE")
        print("=" * 40)
        print(f"‚úÖ Fichiers trait√©s avec succ√®s: {processed_count}")
        print(f"‚ùå Fichiers en erreur: {error_count}")
        print(f"üìä Taux de r√©ussite: {processed_count/(processed_count+error_count)*100:.1f}%")
        
        # Statistiques du cache
        cache_stats = self.translation_service.get_cache_stats()
        print(f"\nüíæ STATISTIQUES DU CACHE:")
        print(f"üìà Taux de hit: {cache_stats['cache_hit_rate']:.1f}%")
        print(f"üè™ Entr√©es totales: {cache_stats['cache_stats']['total_entries']}")
        print(f"üîÑ Hits totaux: {cache_stats['cache_stats']['total_hits']}")
        
        # Sauvegarder les r√©sultats de test
        if test_results:
            test_report_file = self.output_dir / 'analysis' / 'reinsertion_test_results.json'
            with open(test_report_file, 'w', encoding='utf-8') as f:
                json.dump(test_results, f, indent=2, ensure_ascii=False)
            print(f"üìÅ R√©sultats des tests sauvegard√©s dans {test_report_file}")
    
    def process_file_with_strategy(self, file_path: Path, strategy: str) -> bool:
        """Traite un fichier avec une strat√©gie sp√©cifique."""
        try:
            # V√©rification si d√©j√† trait√©
            if not self._is_file_modified(file_path):
                logging.info(f"‚úÖ Fichier d√©j√† trait√©: {file_path.name}")
                return True
            
            logging.info(f"üîÑ D√©but du traitement avec strat√©gie '{strategy}': {file_path.name}")
            
            # Extraction
            texts = self.extract_texts(file_path)
            if not texts:
                logging.warning(f"Aucun texte extrait de {file_path}")
                return True  # Pas d'erreur, juste rien √† traduire
            
            # Traduction
            translated_texts = self.translate_texts(texts, file_path)
            
            # R√©insertion avec strat√©gie adapt√©e
            if strategy == 'default':
                success = self.reinsert_texts(file_path, translated_texts)
            else:
                success = self.reinsertion_manager.apply_strategy(strategy, self, file_path, translated_texts)
            
            if success:
                # Marquer comme trait√©
                self.processed_files[str(file_path)] = self._calculate_file_hash(file_path)
                self._save_processed_files()
                logging.info(f"‚úÖ Traitement termin√© avec succ√®s: {file_path.name}")
                return True
            else:
                logging.error(f"‚ùå √âchec de la r√©insertion: {file_path.name}")
                return False
                
        except Exception as e:
            logging.error(f"‚ùå Erreur lors du traitement de {file_path}: {e}")
            return False
    
    def extract_texts(self, file_path: Path) -> Optional[List[str]]:
        """
        Extraction optimis√©e des textes avec patterns pr√©-compil√©s.
        """
        # Nouveau syst√®me: pas de v√©rification d'extension, on teste tous les fichiers
        out_json = self.output_dir / 'extracted' / (file_path.stem + '.json')

        try:
            with open(file_path, 'rb') as f:
                data = f.read()

            messages = []
            texts = []
            
            # Utiliser les patterns pr√©-compil√©s pour optimiser les performances
            all_matches = set()
            for pattern in self._compiled_patterns:
                matches = pattern.finditer(data)
                for match in matches:
                    if match.group() not in all_matches:
                        all_matches.add(match.group())
                        
                        # Essayer plusieurs encodages
                        text = None
                        for encoding in ['ascii', 'shift_jis', 'utf-8', 'latin1']:
                            try:
                                text = match.group().decode(encoding).strip()
                                if len(text) >= 4 and self._is_likely_game_text(text):
                                    break
                                text = None
                            except:
                                continue
                        
                        if text:
                            offset = match.start()
                            messages.append({
                                'offset': offset,
                                'raw': match.group().hex(),
                                'encoding': encoding,
                                'texts': [text]
                            })
                            texts.append(text)

            # Sauvegarde des messages extraits
            with open(out_json, 'w', encoding='utf-8') as f:
                json.dump(messages, f, ensure_ascii=False, indent=2)
            
            logging.info(f"{len(texts)} textes extraits de {file_path}")
            return texts

        except Exception as e:
            logging.error(f"Erreur extraction: {e}")
            return None
    
    def _is_likely_game_text(self, text: str) -> bool:
        """D√©termine si le texte ressemble √† du texte de jeu traduisible."""
        # Filtres de base
        if len(text.strip()) < 4:
            return False
            
        # Ignore les cha√Ænes qui ne contiennent que des caract√®res sp√©ciaux
        if not any(c.isalpha() for c in text):
            return False
            
        # Ignore les cha√Ænes avec trop de caract√®res r√©p√©t√©s
        if len(set(text)) < len(text) / 3:
            return False
            
        # Ignore les chemins de fichiers √©vidents
        if '/' in text or '\\' in text or text.endswith('.exe'):
            return False
            
        return True

    def translate_texts(self, texts: List[str], file_path: Path = None) -> List[str]:
        """
        Traduit les textes avec le service am√©lior√© (cache, retry, parall√©lisation).
        """
        import time
        import json
        import re
        import sys

        # Liste blanche personnalisable de noms propres √† ne jamais traduire
        whitelist = [
            "Yukari", "Mitsuru", "Fuuka", "Akihiko", "Tartarus", "Nyx", "SEES", "Aigis", "Junpei", "Shinjiro", "Koromaru", "Elizabeth", "Igor", "Pharos", "Ryoji", "Chidori", "Strega", "Ikutsuki", "Takaya", "Jin", "Ken", "Persona", "Evoker", "S.E.E.S.", "Aragaki", "Makoto", "Minato", "Protagonist", "Yamagishi", "Sanada", "Takeba", "Iori", "Amada", "Tanaka", "Velvet Room", "Paulownia Mall", "Gekkoukan", "Mitsuru Kirijo", "Yukari Takeba", "Fuuka Yamagishi", "Akihiko Sanada", "Junpei Iori", "Shinjiro Aragaki", "Ken Amada", "Koromaru", "Aigis", "Elizabeth", "Igor", "Pharos", "Ryoji Mochizuki", "Chidori", "Takaya", "Jin", "Ikutsuki", "Strega", "Nyx Avatar", "Nyx", "Tartarus", "SEES", "Persona", "Evoker", "S.E.E.S."
        ]

        # Filtrer les textes √† traduire
        texts_to_translate = []
        skip_indices = []
        
        for i, text in enumerate(texts):
            # Extraction des tokens et du texte propre
            tokens, clean_text = self.special_tokens.extract_game_tokens(text)
            
            # R√©cup√©ration du contexte
            previous_text = texts[i-1] if i > 0 else None
            next_text = texts[i+1] if i < len(texts)-1 else None
            
            if not clean_text.strip() or self.should_skip_translation(text, whitelist, previous_text, next_text):
                skip_indices.append(i)
            else:
                texts_to_translate.append((i, clean_text, tokens))
        
        # Traduction par batch avec le service am√©lior√©
        print(f"üîÑ Traduction de {len(texts_to_translate)} textes (cache activ√©)...")
        
        if texts_to_translate:
            # Extraire seulement les textes propres pour la traduction
            clean_texts = [item[1] for item in texts_to_translate]
            
            # Utiliser la traduction par batch pour l'efficacit√©
            if len(clean_texts) > 10:  # Batch seulement si assez de textes
                translated_clean = self.translation_service.translate_batch(clean_texts, max_workers=3)
            else:
                # Traduction s√©quentielle pour les petits lots
                translated_clean = []
                for i, clean_text in enumerate(clean_texts, 1):
                    self.print_progress(i, len(clean_texts), clean_text)
                    translated = self.translation_service.translate_with_retry(clean_text)
                    translated_clean.append(translated)
                    time.sleep(0.1)  # Petite pause pour √©viter les limitations
        else:
            translated_clean = []
        
        # Reconstruction des textes complets avec tokens
        translated = texts.copy()  # Commencer par copier tous les textes originaux
        
        for j, (original_index, _, tokens) in enumerate(texts_to_translate):
            if j < len(translated_clean):
                # Reconstruire avec les tokens originaux
                reconstructed = self.special_tokens.reconstruct_text(translated_clean[j], tokens)
                translated[original_index] = reconstructed
        
        print()  # Nouvelle ligne apr√®s la progression
        
        # Afficher les statistiques du cache
        stats = self.translation_service.get_cache_stats()
        print(f"üìä Cache: {stats['cache_hit_rate']:.1f}% hits, "
              f"{stats['cache_stats']['total_entries']} entr√©es")

        # Sauvegarde dans un fichier √† part si file_path est fourni
        if file_path is not None:
            out_json = self.output_dir / 'translated' / (file_path.stem + '_fr.json')
            try:
                with open(out_json, 'w', encoding='utf-8') as f:
                    json.dump(translated, f, ensure_ascii=False, indent=2)
                logging.info(f"Textes traduits sauvegard√©s dans {out_json}")
            except Exception as e:
                logging.error(f"Erreur lors de la sauvegarde des textes traduits : {e}")
        
        return translated
    
    def reinsert_texts(self, file_path, translated_texts: List[str]) -> bool:
        """
        R√©ins√®re les textes traduits dans le fichier original de mani√®re s√©curis√©e.
        Version simplifi√©e et robuste.
        """
        import json
        import shutil
        
        # S'assurer que file_path est un Path object
        if isinstance(file_path, str):
            file_path = Path(file_path)
        elif not isinstance(file_path, Path):
            file_path = Path(str(file_path))
        
        # Cr√©ation du dossier de sortie
        output_dir = self.output_dir / 'reinjected'
        output_dir.mkdir(exist_ok=True)
        out_file = output_dir / file_path.name
        
        try:
            # Chargement du fichier d'extraction
            extracted_json = self.output_dir / 'extracted' / (file_path.stem + '.json')
            if not extracted_json.exists():
                logging.error(f"Fichier d'extraction manquant : {extracted_json}")
                return False
                
            with open(extracted_json, 'r', encoding='utf-8') as f:
                messages = json.load(f)
                
            if len(messages) != len(translated_texts):
                logging.error(f"Nombre de textes traduits ({len(translated_texts)}) != messages extraits ({len(messages)})")
                return False
            
            # Lecture du fichier original
            with open(file_path, 'rb') as f:
                data = bytearray(f.read())
            
            # Pr√©paration des remplacements (en ordre inverse pour ne pas d√©caler les offsets)
            replacements = []
            for msg, new_text in zip(messages, translated_texts):
                if 'offset' in msg and 'texts' in msg and msg['texts']:
                    old_text = msg['texts'][0]
                    
                    # Essai de diff√©rents encodages pour le texte original
                    old_bytes = None
                    used_encoding = 'utf-8'  # Commencer par UTF-8 pour supporter les caract√®res fran√ßais
                    for encoding in ['utf-8', 'ascii', 'shift_jis', 'latin1']:
                        try:
                            test_bytes = old_text.encode(encoding)
                            if data.find(test_bytes) != -1:
                                old_bytes = test_bytes
                                used_encoding = encoding
                                break
                        except:
                            continue
                    
                    if old_bytes is None:
                        logging.warning(f"Impossible de trouver '{old_text}' dans le fichier")
                        continue
                    
                    # Encodage du nouveau texte avec le m√™me encodage
                    try:
                        new_bytes = new_text.encode(used_encoding)
                    except UnicodeEncodeError:
                        # Si l'encodage original ne supporte pas le fran√ßais, essayer UTF-8
                        try:
                            new_bytes = new_text.encode('utf-8')
                            used_encoding = 'utf-8'
                            logging.info(f"Passage en UTF-8 pour '{new_text}' (caract√®res fran√ßais d√©tect√©s)")
                        except:
                            logging.warning(f"Impossible d'encoder '{new_text}', utilisation de l'original")
                            new_bytes = old_bytes
                    
                    # STRAT√âGIE SANS LIMITATION: R√©int√©grer TOUS les textes peu importe la taille
                    if len(new_bytes) > len(old_bytes):
                        # Aucune limitation ! Traduction compl√®te avec expansion automatique
                        overflow = len(new_bytes) - len(old_bytes)
                        expansion_percent = (overflow / len(old_bytes)) * 100
                        logging.info(f"üöÄ Expansion automatique: '{old_text}' -> '{new_text}' (+{overflow} bytes, +{expansion_percent:.1f}%)")
                        # new_bytes reste inchang√© - expansion compl√®te garantie !
                        
                    elif len(new_bytes) < len(old_bytes):
                        # Padding avec des espaces ou des z√©ros
                        if used_encoding in ['ascii', 'utf-8', 'latin1']:
                            padding_char = b' '
                        else:
                            padding_char = b'\x00'
                        new_bytes = new_bytes + padding_char * (len(old_bytes) - len(new_bytes))
                    
                    # Recherche de la position du texte original
                    offset = data.find(old_bytes)
                    if offset != -1:
                        replacements.append({
                            'offset': offset,
                            'old_bytes': old_bytes,
                            'new_bytes': new_bytes
                        })
                    else:
                        logging.warning(f"Texte original non trouv√© dans le fichier: '{old_text}'")
            
            # Application des remplacements avec gestion dynamique de la taille
            replacements.sort(key=lambda x: x['offset'], reverse=True)
            successful_replacements = 0
            total_size_change = 0
            
            for replacement in replacements:
                offset = replacement['offset']
                old_bytes = replacement['old_bytes']
                new_bytes = replacement['new_bytes']
                
                # Ajuster l'offset si des remplacements pr√©c√©dents ont chang√© la taille
                adjusted_offset = offset + total_size_change
                
                # V√©rification de s√©curit√© avec offset ajust√©
                if adjusted_offset >= 0 and adjusted_offset + len(old_bytes) <= len(data):
                    if data[adjusted_offset:adjusted_offset+len(old_bytes)] == old_bytes:
                        # Calculer le changement de taille
                        size_diff = len(new_bytes) - len(old_bytes)
                        
                        # Remplacer avec la nouvelle taille (peut √™tre plus grande !)
                        data[adjusted_offset:adjusted_offset+len(old_bytes)] = new_bytes
                        
                        # Mettre √† jour le changement total de taille
                        total_size_change += size_diff
                        successful_replacements += 1
                        
                        if size_diff > 0:
                            logging.info(f"‚úÖ Remplacement √©tendu r√©ussi √† l'offset {adjusted_offset} (+{size_diff} bytes)")
                        else:
                            logging.debug(f"Remplacement r√©ussi √† l'offset {adjusted_offset}")
                    else:
                        logging.warning(f"Donn√©es √† l'offset {adjusted_offset} ne correspondent pas, remplacement ignor√©")
                else:
                    logging.warning(f"Offset {adjusted_offset} hors limites, remplacement ignor√©")
            
            logging.info(f"üìä {successful_replacements}/{len(replacements)} remplacements r√©ussis, taille finale: {len(data)} bytes")
            
            # Sauvegarde du fichier modifi√©
            with open(out_file, 'wb') as f:
                f.write(data)
            logging.info(f"Fichier r√©inject√© sauvegard√© : {out_file}")
            
            # Copie de s√©curit√© de l'original (si ce n'est pas d√©j√† fait)
            backup_file = file_path.with_suffix(file_path.suffix + '.backup')
            if not backup_file.exists():
                shutil.copy2(file_path, backup_file)
                logging.info(f"Sauvegarde cr√©√©e : {backup_file}")
            
            # Remplacement du fichier original
            try:
                shutil.copy2(out_file, file_path)
                logging.info(f"Fichier original mis √† jour : {file_path}")
                return True
            except Exception as e:
                logging.error(f"Erreur lors de la mise √† jour du fichier original : {e}")
                logging.info(f"Le fichier traduit est disponible dans : {out_file}")
                return False
                
        except Exception as e:
            logging.error(f"Erreur lors de la r√©insertion : {e}")
            return False
    
    def validate_integration_quality(self, file_path: Path) -> Dict:
        """
        Valide la qualit√© de l'int√©gration apr√®s r√©insertion avec suggestions d√©taill√©es.
        Retourne un rapport d√©taill√©.
        """
        try:
            # Extraire les textes du fichier modifi√©
            new_texts = self.extract_texts(file_path)
            
            # Analyser le statut de traduction
            translation_status = self.file_analyzer.detect_translation_status(file_path)
            
            # Statistiques de base
            validation_report = {
                'file': str(file_path),
                'texts_found': len(new_texts) if new_texts else 0,
                'translation_status': translation_status['status'],
                'french_ratio': translation_status['confidence'],
                'quality_score': 0.0,
                'recommendations': [],
                'detailed_analysis': {},
                'suggestions': []
            }
            
            if new_texts and len(new_texts) > 0:
                # Analyse d√©taill√©e de la qualit√©
                french_count = translation_status.get('french_indicators', 0)
                english_count = translation_status.get('english_indicators', 0)
                total_indicators = french_count + english_count
                
                # Calcul du score de qualit√©
                if total_indicators > 0:
                    french_ratio = french_count / total_indicators
                    validation_report['quality_score'] = french_ratio
                    
                    # Analyse d√©taill√©e
                    validation_report['detailed_analysis'] = {
                        'french_indicators': french_count,
                        'english_indicators': english_count,
                        'total_texts': len(new_texts),
                        'translation_coverage': french_ratio,
                        'estimated_completion': min(100, french_ratio * 100)
                    }
                    
                    # Recommandations bas√©es sur la qualit√©
                    if french_ratio >= 0.9:
                        validation_report['recommendations'].append("üåü Excellente qualit√© - Traduction quasi-compl√®te")
                        validation_report['suggestions'].append("Consid√©rez ce fichier comme termin√©")
                    elif french_ratio >= 0.7:
                        validation_report['recommendations'].append("‚úÖ Tr√®s bonne qualit√© de traduction")
                        validation_report['suggestions'].append("Quelques textes pourraient n√©cessiter une r√©vision")
                    elif french_ratio >= 0.5:
                        validation_report['recommendations'].append("‚úÖ Bonne qualit√© de traduction")
                        validation_report['suggestions'].append("Re-traitement recommand√© pour am√©liorer la couverture")
                    elif french_ratio >= 0.3:
                        validation_report['recommendations'].append("‚ö†Ô∏è Traduction partielle d√©tect√©e")
                        validation_report['suggestions'].append("V√©rifiez les param√®tres d'extraction et de r√©insertion")
                    elif french_ratio >= 0.1:
                        validation_report['recommendations'].append("‚ùå Peu de traductions d√©tect√©es")
                        validation_report['suggestions'].append("Le fichier pourrait n√©cessiter un traitement sp√©cialis√©")
                    else:
                        validation_report['recommendations'].append("‚ùå Traduction non d√©tect√©e")
                        validation_report['suggestions'].append("V√©rifiez la compatibilit√© du format de fichier")
                    
                    # Suggestions sp√©cifiques selon le ratio
                    if english_count > french_count * 2:
                        validation_report['suggestions'].append("Nombreux textes anglais restants - consid√©rez un re-traitement")
                    
                    if french_count > 0 and english_count == 0:
                        validation_report['suggestions'].append("Traduction compl√®te d√©tect√©e - excellent travail!")
                    
                    # Analyse de la longueur des textes
                    if new_texts:
                        avg_length = sum(len(text) for text in new_texts) / len(new_texts)
                        validation_report['detailed_analysis']['average_text_length'] = avg_length
                        
                        if avg_length < 5:
                            validation_report['suggestions'].append("Textes tr√®s courts - possibles codes ou identifiants")
                        elif avg_length > 100:
                            validation_report['suggestions'].append("Textes longs d√©tect√©s - v√©rifiez l'int√©grit√©")
                
                else:
                    validation_report['recommendations'].append("‚ÑπÔ∏è Aucun indicateur de langue d√©tect√©")
                    validation_report['suggestions'].append("Fichier peut ne pas contenir de texte traduisible")
            else:
                validation_report['recommendations'].append("‚ö†Ô∏è Aucun texte extrait du fichier")
                validation_report['suggestions'].append("V√©rifiez le format et la compatibilit√© du fichier")
            
            # Analyse de la taille du fichier
            file_size = file_path.stat().st_size
            validation_report['file_size'] = file_size
            validation_report['detailed_analysis']['file_size_kb'] = file_size // 1024
            
            if file_size > 1024 * 1024:  # > 1MB
                validation_report['recommendations'].append(f"üìä Fichier volumineux: {file_size // 1024}KB")
                validation_report['suggestions'].append("Expansion r√©ussie - traductions longues int√©gr√©es")
            elif file_size > 100 * 1024:  # > 100KB
                validation_report['suggestions'].append("Taille normale pour un fichier de jeu")
            else:
                validation_report['suggestions'].append("Fichier petit - peut contenir peu de texte")
            
            # Score global bas√© sur plusieurs facteurs
            size_factor = min(1.0, file_size / (100 * 1024))  # Normaliser sur 100KB
            text_factor = min(1.0, len(new_texts) / 10) if new_texts else 0  # Normaliser sur 10 textes
            
            final_score = (
                validation_report['quality_score'] * 0.6 +  # 60% qualit√© traduction
                size_factor * 0.2 +                         # 20% taille fichier
                text_factor * 0.2                           # 20% nombre de textes
            )
            validation_report['quality_score'] = round(final_score, 3)
            
            return validation_report
            
        except Exception as e:
            return {
                'file': str(file_path),
                'error': str(e),
                'quality_score': 0.0,
                'recommendations': [f"‚ùå Erreur de validation: {e}"],
                'suggestions': ["V√©rifiez l'int√©grit√© du fichier et les permissions"],
                'detailed_analysis': {'error': True}
            }
    
    def process_file(self, file_path: Path) -> bool:
        """Traite un fichier complet (extraction, traduction, r√©insertion)."""
        # V√©rification si le fichier a d√©j√† √©t√© trait√©
        if not self._is_file_modified(file_path):
            logging.info(f"‚úÖ Fichier d√©j√† trait√© et non modifi√©: {file_path.name}")
            return True
            
        logging.info(f"üîÑ D√©but du traitement: {file_path.name}")
        
        try:
            # √âtape 1: Extraction
            logging.info(f"  üì§ Extraction des textes...")
            texts = self.extract_texts(file_path)
            if texts is None:
                logging.error(f"  ‚ùå √âchec de l'extraction")
                return False
                
            # V√©rification si le fichier contient des textes √† traduire
            if not texts:
                logging.info(f"  ‚ÑπÔ∏è Aucun texte √† traduire trouv√©, fichier marqu√© comme trait√©")
                # Enregistrer le fichier comme trait√© m√™me s'il n'y a pas de textes
                self.processed_files[str(file_path)] = self._calculate_file_hash(file_path)
                self._save_processed_files()
                return True
            
            logging.info(f"  üìù {len(texts)} texte(s) extrait(s)")
            
            # √âtape 2: Traduction
            logging.info(f"  üîÑ Traduction en cours...")
            translated_texts = self.translate_texts(texts, file_path)
            
            # √âtape 3: R√©insertion
            logging.info(f"  üì• R√©insertion des textes traduits...")
            if not self.reinsert_texts(file_path, translated_texts):
                logging.error(f"  ‚ùå √âchec de la r√©insertion")
                return False
            
            # √âtape 4: Validation de la qualit√©
            logging.info(f"  üîç Validation de la qualit√© d'int√©gration...")
            validation = self.validate_integration_quality(file_path)
            
            quality_score = validation['quality_score']
            logging.info(f"  üìä Score de qualit√©: {quality_score:.1%}")
            
            for recommendation in validation['recommendations']:
                logging.info(f"  {recommendation}")
            
            if quality_score >= 0.5:
                logging.info(f"  ‚úÖ Qualit√© d'int√©gration valid√©e")
            else:
                logging.warning(f"  ‚ö†Ô∏è Qualit√© d'int√©gration √† v√©rifier manuellement")
            
            logging.info(f"  ‚úÖ Traitement termin√© avec succ√®s")
            
            # Mise √† jour du hash du fichier
            self.processed_files[str(file_path)] = self._calculate_file_hash(file_path)
            self._save_processed_files()
            return True
            
        except Exception as e:
            logging.error(f"  ‚ùå Erreur lors du traitement de {file_path.name}: {str(e)}")
            return False
    
    def process_directory(self):
        """Traite tous les fichiers du r√©pertoire du jeu avec l'ancienne m√©thode."""
        print("üîÑ Mode de traitement traditionnel activ√©...")
        print("üí° Utilisez --auto pour le nouveau mode d'analyse automatique")
        
        processed_count = 0
        error_count = 0
        ignored_count = 0
        
        # Recherche de tous les fichiers support√©s (ancienne m√©thode)
        all_files = []
        for root, _, files in os.walk(self.game_dir):
            for file in files:
                file_path = Path(root) / file
                # Ignorer les fichiers .backup
                if file_path.suffix.lower() == '.backup' or '.backup' in file_path.name:
                    ignored_count += 1
                    continue
                if file_path.suffix.lower() in self.supported_extensions:
                    all_files.append(file_path)
        
        if not all_files:
            print(f"‚ùå Aucun fichier support√© trouv√© dans {self.game_dir}")
            print(f"üìÅ Extensions support√©es: {', '.join(self.supported_extensions)}")
            if ignored_count > 0:
                print(f"üö´ {ignored_count} fichier(s) .backup ignor√©(s)")
            return
            
        print(f"üìä {len(all_files)} fichier(s) trouv√©(s) √† traiter")
        if ignored_count > 0:
            print(f"üö´ {ignored_count} fichier(s) .backup ignor√©(s)")
        
        for i, file_path in enumerate(all_files, 1):
            print(f"\nüìÑ [{i}/{len(all_files)}] Traitement: {file_path.name}")
            try:
                if self.process_file(file_path):
                    processed_count += 1
                    print(f"‚úÖ Succ√®s")
                else:
                    error_count += 1
                    print(f"‚ùå √âchec")
            except Exception as e:
                error_count += 1
                print(f"‚ùå Erreur: {e}")
                
        print(f"\nüìà R√©sum√©: {processed_count} r√©ussis, {error_count} √©checs")
    
    def test_mode(self):
        """Mode test pour analyser les fichiers sans traduction."""
        print("üß™ Mode test activ√© - Analyse des fichiers...")
        
        for root, _, files in os.walk(self.game_dir):
            for file in files:
                file_path = Path(root) / file
                if file_path.suffix.lower() in self.supported_extensions:
                    print(f"\nüìÑ Analyse: {file_path}")
                    
                    try:
                        texts = self.extract_texts(file_path)
                        if texts:
                            print(f"  üìù {len(texts)} texte(s) extrait(s)")
                            # Afficher les premiers textes
                            for i, text in enumerate(texts[:5]):
                                print(f"    {i+1}. {text[:60]}...")
                            if len(texts) > 5:
                                print(f"    ... et {len(texts)-5} autre(s)")
                        else:
                            print(f"  ‚ùå Aucun texte extrait")
                    except Exception as e:
                        print(f"  ‚ùå Erreur: {e}")

    def print_progress(self, current: int, total: int, text: str):
        """Affiche la progression de la traduction avec le texte en cours."""
        progress = (current / total) * 100
        sys.stdout.write(f"\rTraduction en cours : {progress:.1f}% - Texte {current}/{total}: {text[:50]}...")
        sys.stdout.flush()

    def should_skip_translation(self, text: str, whitelist: List[str], previous_text: str = None, next_text: str = None) -> bool:
        """Version simplifi√©e qui traduit plus de textes."""
        clean_text = text.strip()
        
        # Si le texte est vide
        if not clean_text:
            return True
            
        # Si le texte est dans la whitelist des noms propres
        if any(name.lower() in clean_text.lower() for name in whitelist):
            return False  # On traduit quand m√™me pour le contexte
            
        # Patterns vraiment critiques √† ignorer
        skip_patterns = [
            r'^\d+$',                    # Nombres seuls
            r'^[A-Z0-9_]{6,}$',         # Codes longs en majuscules
            r'^[\x00-\x1F]+$',          # Caract√®res de contr√¥le
            r'^[!@#$%^&*()_+\-=\[\]{};\'"\\|,.<>\/?]+$',  # Que des symboles
        ]
        
        for pattern in skip_patterns:
            if re.match(pattern, clean_text):
                return True
        
        # Si c'est trop court et sans voyelles
        if len(clean_text) < 3 and not any(v in clean_text.lower() for v in 'aeiouy'):
            return True
            
        return False

class P3FESTranslatorGUI:
    """Interface graphique simple pour le traducteur."""
    
    def __init__(self):
        if not GUI_AVAILABLE:
            raise ImportError("Interface graphique non disponible")
        
        self.root = tk.Tk()
        self.root.title("Persona 3 FES - Traducteur Fran√ßais")
        self.root.geometry("800x600")
        
        self.translator = None
        self.processing = False
        
        self.setup_ui()
    
    def setup_ui(self):
        """Configure l'interface utilisateur."""
        # Frame principal
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Configuration des chemins
        paths_frame = ttk.LabelFrame(main_frame, text="Configuration des chemins", padding="10")
        paths_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5)
        
        ttk.Label(paths_frame, text="Dossier du jeu:").grid(row=0, column=0, sticky=tk.W, pady=2)
        self.game_dir_var = tk.StringVar(value="GameFiles")
        ttk.Entry(paths_frame, textvariable=self.game_dir_var, width=50).grid(row=0, column=1, padx=5)
        ttk.Button(paths_frame, text="Parcourir", command=self.browse_game_dir).grid(row=0, column=2)
        
        ttk.Label(paths_frame, text="Dossier de sortie:").grid(row=1, column=0, sticky=tk.W, pady=2)
        self.output_dir_var = tk.StringVar(value="TranslatedFiles")
        ttk.Entry(paths_frame, textvariable=self.output_dir_var, width=50).grid(row=1, column=1, padx=5)
        ttk.Button(paths_frame, text="Parcourir", command=self.browse_output_dir).grid(row=1, column=2)
        
        # Options
        options_frame = ttk.LabelFrame(main_frame, text="Options", padding="10")
        options_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5)
        
        self.test_mode_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(options_frame, text="Mode test (recommand√©)", variable=self.test_mode_var).grid(row=0, column=0, sticky=tk.W)
        
        self.parallel_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(options_frame, text="Mode parall√©lis√©", variable=self.parallel_var).grid(row=0, column=1, sticky=tk.W)
        
        ttk.Label(options_frame, text="Score minimum:").grid(row=1, column=0, sticky=tk.W, pady=2)
        self.min_score_var = tk.DoubleVar(value=0.4)
        ttk.Scale(options_frame, from_=0.1, to=1.0, variable=self.min_score_var, orient=tk.HORIZONTAL).grid(row=1, column=1, sticky=(tk.W, tk.E))
        self.score_label = ttk.Label(options_frame, text="0.4")
        self.score_label.grid(row=1, column=2)
        
        self.min_score_var.trace('w', self.update_score_label)
        
        # Boutons d'action
        buttons_frame = ttk.Frame(main_frame)
        buttons_frame.grid(row=2, column=0, columnspan=2, pady=10)
        
        ttk.Button(buttons_frame, text="Analyser les fichiers", command=self.analyze_files).grid(row=0, column=0, padx=5)
        ttk.Button(buttons_frame, text="Traitement automatique", command=self.auto_process).grid(row=0, column=1, padx=5)
        ttk.Button(buttons_frame, text="Voir le progr√®s", command=self.show_progress).grid(row=0, column=2, padx=5)
        ttk.Button(buttons_frame, text="Stats du cache", command=self.show_cache_stats).grid(row=0, column=3, padx=5)
        
        # Zone de texte pour les logs
        log_frame = ttk.LabelFrame(main_frame, text="Journal", padding="5")
        log_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)
        
        self.log_text = tk.Text(log_frame, height=15, wrap=tk.WORD)
        scrollbar = ttk.Scrollbar(log_frame, orient=tk.VERTICAL, command=self.log_text.yview)
        self.log_text.configure(yscrollcommand=scrollbar.set)
        
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        # Barre de progression
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(main_frame, variable=self.progress_var, maximum=100)
        self.progress_bar.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5)
        
        # Status bar
        self.status_var = tk.StringVar(value="Pr√™t")
        status_bar = ttk.Label(main_frame, textvariable=self.status_var, relief=tk.SUNKEN)
        status_bar.grid(row=5, column=0, columnspan=2, sticky=(tk.W, tk.E))
        
        # Configuration de la grille
        main_frame.columnconfigure(1, weight=1)
        main_frame.rowconfigure(3, weight=1)
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        paths_frame.columnconfigure(1, weight=1)
        options_frame.columnconfigure(1, weight=1)
    
    def update_score_label(self, *args):
        """Met √† jour l'affichage du score."""
        self.score_label.config(text=f"{self.min_score_var.get():.1f}")
    
    def browse_game_dir(self):
        """S√©lectionne le dossier du jeu."""
        dir_path = filedialog.askdirectory(title="S√©lectionner le dossier du jeu")
        if dir_path:
            self.game_dir_var.set(dir_path)
    
    def browse_output_dir(self):
        """S√©lectionne le dossier de sortie."""
        dir_path = filedialog.askdirectory(title="S√©lectionner le dossier de sortie")
        if dir_path:
            self.output_dir_var.set(dir_path)
    
    def log(self, message):
        """Ajoute un message au journal."""
        self.log_text.insert(tk.END, message + "\n")
        self.log_text.see(tk.END)
        self.root.update()
    
    def get_translator(self):
        """Obtient une instance du traducteur."""
        if not self.translator:
            self.translator = P3FESTranslator(self.game_dir_var.get(), self.output_dir_var.get())
        return self.translator
    
    def analyze_files(self):
        """Lance l'analyse des fichiers."""
        if self.processing:
            return
        
        self.processing = True
        self.status_var.set("Analyse en cours...")
        self.progress_var.set(0)
        
        try:
            translator = self.get_translator()
            self.log("üîç D√©but de l'analyse des fichiers...")
            
            analysis_report = translator.analyze_all_files()
            
            # Afficher les r√©sultats
            self.log(f"üìä Analyse termin√©e !")
            self.log(f"üìÅ Fichiers analys√©s: {analysis_report['analyzed_files']}")
            self.log(f"üéØ Fichiers √† traiter: {len(analysis_report['untranslated_files'])}")
            self.log(f"‚úÖ Fichiers traduits: {len(analysis_report['translated_files'])}")
            
            summary = analysis_report['translation_summary']
            if summary['fully_translated'] > 0:
                progress = (summary['fully_translated'] / analysis_report['analyzed_files']) * 100
                self.progress_var.set(progress)
                self.log(f"üìà Progr√®s: {progress:.1f}%")
            
            self.status_var.set("Analyse termin√©e")
            
        except Exception as e:
            self.log(f"‚ùå Erreur: {e}")
            messagebox.showerror("Erreur", f"Erreur lors de l'analyse: {e}")
        finally:
            self.processing = False
    
    def auto_process(self):
        """Lance le traitement automatique."""
        if self.processing:
            return
        
        if not messagebox.askyesno("Confirmation", "Lancer le traitement automatique ?"):
            return
        
        self.processing = True
        self.status_var.set("Traitement en cours...")
        
        try:
            translator = self.get_translator()
            self.log("üöÄ D√©but du traitement automatique...")
            
            # Cette m√©thode devrait √™tre adapt√©e pour utiliser des callbacks
            translator.auto_process_directory(
                test_mode=self.test_mode_var.get(),
                min_score=self.min_score_var.get()
            )
            
            self.log("‚úÖ Traitement automatique termin√© !")
            self.status_var.set("Traitement termin√©")
            
        except Exception as e:
            self.log(f"‚ùå Erreur: {e}")
            messagebox.showerror("Erreur", f"Erreur lors du traitement: {e}")
        finally:
            self.processing = False
    
    def show_progress(self):
        """Affiche le progr√®s d√©taill√©."""
        try:
            translator = self.get_translator()
            if not translator.analysis_report:
                translator.analyze_all_files()
            
            summary = translator.analysis_report['translation_summary']
            total = translator.analysis_report['analyzed_files']
            
            progress_text = f"üìä PROGR√àS DE TRADUCTION:\n"
            progress_text += f"üìÅ Total: {total} fichiers\n"
            progress_text += f"‚úÖ Traduits: {summary['fully_translated']} ({summary['fully_translated']/total*100:.1f}%)\n"
            progress_text += f"üî∂ Partiels: {summary['partially_translated']}\n"
            progress_text += f"‚ùå Non traduits: {summary['not_translated']}\n"
            
            messagebox.showinfo("Progr√®s de traduction", progress_text)
            
        except Exception as e:
            messagebox.showerror("Erreur", f"Erreur: {e}")
    
    def show_cache_stats(self):
        """Affiche les statistiques du cache."""
        try:
            translator = self.get_translator()
            stats = translator.translation_service.get_cache_stats()
            
            stats_text = f"üíæ STATISTIQUES DU CACHE:\n"
            stats_text += f"üìä Taux de hit: {stats['cache_hit_rate']:.1f}%\n"
            stats_text += f"üè™ Entr√©es: {stats['cache_stats']['total_entries']}\n"
            stats_text += f"üîÑ Hits: {stats['cache_stats']['total_hits']}\n"
            stats_text += f"üÜï R√©centes: {stats['cache_stats']['recent_entries']}\n"
            
            messagebox.showinfo("Statistiques du cache", stats_text)
            
        except Exception as e:
            messagebox.showerror("Erreur", f"Erreur: {e}")
    
    def run(self):
        """Lance l'interface graphique."""
        self.log("üéÆ Interface graphique du traducteur Persona 3 FES")
        self.log("üí° S√©lectionnez les dossiers et cliquez sur 'Analyser les fichiers' pour commencer")
        self.root.mainloop()

def main():
    """Point d'entr√©e principal du programme."""
    import argparse
    import sys
    
    parser = argparse.ArgumentParser(description='Traducteur automatique pour Persona 3 FES')
    parser.add_argument('--game-dir', default='GameFiles', help='Dossier contenant les fichiers du jeu')
    parser.add_argument('--output-dir', default='TranslatedFiles', help='Dossier de sortie')
    parser.add_argument('--file', help='Traduire un fichier sp√©cifique')
    parser.add_argument('--test', action='store_true', help='Mode test (analyse sans traduction)')
    parser.add_argument('--verbose', action='store_true', help='Mode verbose')
    parser.add_argument('--gui', action='store_true', help='Lancer l\'interface graphique')
    
    # Nouvelles options pour l'analyse automatique
    parser.add_argument('--analyze', action='store_true', help='Analyser tous les fichiers pour d√©tecter le contenu traduisible')
    parser.add_argument('--auto', action='store_true', help='Mode automatique: analyse + traitement intelligent')
    parser.add_argument('--auto-test', action='store_true', help='Mode automatique avec test des m√©thodes de r√©insertion')
    parser.add_argument('--min-score', type=float, default=0.4, help='Score minimum pour consid√©rer un fichier (0.0-1.0)')
    parser.add_argument('--max-files', type=int, help='Limite le nombre de fichiers √† analyser')
    parser.add_argument('--remaining', action='store_true', help='Affiche seulement les fichiers restants √† traduire')
    parser.add_argument('--progress', action='store_true', help='Affiche le progr√®s de traduction et statistiques d√©taill√©es')
    parser.add_argument('--validate', action='store_true', help='Valide la qualit√© des traductions dans les fichiers existants')
    parser.add_argument('--validate-file', help='Valide la qualit√© de traduction d\'un fichier sp√©cifique')
    parser.add_argument('--cache-stats', action='store_true', help='Affiche les statistiques du cache de traduction')
    parser.add_argument('--clean-cache', action='store_true', help='Nettoie le cache de traduction expir√©')
    parser.add_argument('--parallel', action='store_true', help='Force le mode parall√©lis√© m√™me pour peu de fichiers')
    
    # Nouvelle option pour la strat√©gie de traduction
    parser.add_argument('--strategy', choices=['professional', 'preserve', 'mixed'], 
                       default='professional', 
                       help='Strat√©gie pour g√©rer les traductions trop longues (d√©faut: professional)')
    parser.add_argument('--show-strategies', action='store_true', 
                       help='Affiche les strat√©gies disponibles et leurs descriptions')
    
    args = parser.parse_args()
    
    # Interface graphique
    if args.gui:
        if not GUI_AVAILABLE:
            print("‚ùå Interface graphique non disponible (tkinter manquant)")
            sys.exit(1)
        
        try:
            app = P3FESTranslatorGUI()
            app.run()
            return
        except Exception as e:
            print(f"‚ùå Erreur interface graphique: {e}")
            sys.exit(1)
    
    # Nouvelles options pour l'analyse automatique
    parser.add_argument('--analyze', action='store_true', help='Analyser tous les fichiers pour d√©tecter le contenu traduisible')
    parser.add_argument('--auto', action='store_true', help='Mode automatique: analyse + traitement intelligent')
    parser.add_argument('--auto-test', action='store_true', help='Mode automatique avec test des m√©thodes de r√©insertion')
    parser.add_argument('--min-score', type=float, default=0.4, help='Score minimum pour consid√©rer un fichier (0.0-1.0)')
    parser.add_argument('--max-files', type=int, help='Limite le nombre de fichiers √† analyser')
    parser.add_argument('--remaining', action='store_true', help='Affiche seulement les fichiers restants √† traduire')
    parser.add_argument('--progress', action='store_true', help='Affiche le progr√®s de traduction et statistiques d√©taill√©es')
    parser.add_argument('--validate', action='store_true', help='Valide la qualit√© des traductions dans les fichiers existants')
    parser.add_argument('--validate-file', help='Valide la qualit√© de traduction d\'un fichier sp√©cifique')
    parser.add_argument('--cache-stats', action='store_true', help='Affiche les statistiques du cache de traduction')
    parser.add_argument('--clean-cache', action='store_true', help='Nettoie le cache de traduction expir√©')
    parser.add_argument('--parallel', action='store_true', help='Force le mode parall√©lis√© m√™me pour peu de fichiers')
    
    # Nouvelle option pour la strat√©gie de traduction
    parser.add_argument('--strategy', choices=['professional', 'preserve', 'mixed'], 
                       default='professional', 
                       help='Strat√©gie pour g√©rer les traductions trop longues (d√©faut: professional)')
    parser.add_argument('--show-strategies', action='store_true', 
                       help='Affiche les strat√©gies disponibles et leurs descriptions')
    
    args = parser.parse_args()
    
    # Afficher les strat√©gies disponibles si demand√©
    if args.show_strategies:
        print("üéØ Strat√©gies de Traduction:")
        print("=" * 40)
        print("üìã AGGRESSIVE - Aucune limitation de taille")
        print("   R√©int√®gre TOUS les textes peu importe leur longueur")
        print("   ‚Ä¢ Pr√©serve la qualit√©: ‚úÖ")
        print("   ‚Ä¢ Traductions compl√®tes: ‚úÖ") 
        print("   ‚Ä¢ Aucune troncature: ‚úÖ")
        print(f"\nüí° Mode actuel: R√©int√©gration sans limitation")
        return
    
    print(f"üéÆ Strat√©gie de traduction: {args.strategy.upper()}")
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # V√©rification que le dossier de jeu existe
    if not Path(args.game_dir).exists():
        print(f"‚ùå Erreur: Le dossier '{args.game_dir}' n'existe pas.")
        print(f"üìÅ Cr√©ez le dossier et placez-y vos fichiers .pm1, .pac, .pak, .bf, .tbl")
        sys.exit(1)
    
    try:
        translator = P3FESTranslator(args.game_dir, args.output_dir)
        
        if args.file:
            # Traitement d'un fichier sp√©cifique
            file_path = Path(args.file)
            if file_path.exists():
                print(f"üîÑ Traitement du fichier: {file_path}")
                success = translator.process_file(file_path)
                print(f"‚úÖ Succ√®s" if success else f"‚ùå √âchec")
            else:
                print(f"‚ùå Fichier non trouv√©: {file_path}")
                
        elif args.analyze:
            # Mode analyse seulement
            print("üîç Mode analyse - D√©tection des fichiers traduisibles...")
            analysis_report = translator.analyze_all_files(args.max_files)
            translator.print_analysis_summary()
            
        elif args.remaining:
            # Mode affichage des fichiers restants
            print("üìã Analyse des fichiers restants √† traduire...")
            analysis_report = translator.analyze_all_files(args.max_files)
            
            remaining_files = translator.get_promising_files(args.min_score, exclude_translated=True)
            translated_files = len(analysis_report.get('translated_files', []))
            
            print(f"\nüìä FICHIERS RESTANTS √Ä TRADUIRE")
            print("=" * 35)
            print(f"‚úÖ Fichiers d√©j√† traduits: {translated_files}")
            print(f"üéØ Fichiers restants: {len(remaining_files)}")
            
            if remaining_files:
                print(f"\nüìã LISTE DES FICHIERS √Ä TRADUIRE:")
                for i, file_path in enumerate(remaining_files, 1):
                    # Obtenir les infos d√©taill√©es
                    file_info = None
                    for info in analysis_report['untranslated_files']:
                        if Path(info['path']) == file_path:
                            file_info = info
                            break
                    
                    if file_info:
                        score = file_info['text_score']
                        format_name = file_info['format']
                        size_kb = file_info['size'] // 1024
                        print(f"  {i:2d}. {file_path.name}")
                        print(f"      Score: {score:.1%} | Format: {format_name} | Taille: {size_kb}KB")
                    else:
                        print(f"  {i:2d}. {file_path.name}")
                
                estimated_time = len(remaining_files) * 2  # 2 minutes par fichier en moyenne
                print(f"\n‚è±Ô∏è Temps estim√©: ~{estimated_time} minutes")
                print(f"üí° Commande recommand√©e: python p3fes_translator.py --auto-test")
            else:
                print(f"\nüéâ F√âLICITATIONS ! Tous les fichiers semblent d√©j√† traduits !")
                
        elif args.progress:
            # Mode affichage du progr√®s d√©taill√©
            print("üìà Analyse du progr√®s de traduction...")
            analysis_report = translator.analyze_all_files(args.max_files)
            
            summary = analysis_report['translation_summary']
            total_files = analysis_report['analyzed_files']
            translated = summary['fully_translated']
            partial = summary['partially_translated']
            untranslated = summary['not_translated']
            
            print(f"\nüìä PROGR√àS DE TRADUCTION D√âTAILL√â")
            print("=" * 40)
            print(f"üìÅ Total des fichiers: {total_files}")
            print(f"‚úÖ Traduits: {translated} ({translated/total_files*100:.1f}%)")
            print(f"üî∂ Partiellement: {partial} ({partial/total_files*100:.1f}%)")
            print(f"‚ùå Non traduits: {untranslated} ({untranslated/total_files*100:.1f}%)")
            
            # Barre de progr√®s ASCII
            progress_percent = (translated / total_files) * 100 if total_files > 0 else 0
            bar_length = 30
            filled_length = int(bar_length * translated // total_files) if total_files > 0 else 0
            bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)
            print(f"\nüìà [{bar}] {progress_percent:.1f}%")
            
            # Statistiques par format
            print(f"\nüìã PROGR√àS PAR FORMAT:")
            for format_name, files in analysis_report['by_format'].items():
                if files:
                    format_translated = len([f for f in files if f.get('translation_status') == 'fully_translated'])
                    format_total = len(files)
                    format_percent = (format_translated / format_total * 100) if format_total > 0 else 0
                    print(f"  ‚Ä¢ {format_name}: {format_translated}/{format_total} ({format_percent:.1f}%)")
            
            remaining_count = len(analysis_report.get('untranslated_files', []))
            if remaining_count > 0:
                print(f"\nüéØ {remaining_count} fichier(s) restant(s) √† traiter")
                print(f"üí° Utilisez --remaining pour voir la liste d√©taill√©e")
            
        elif args.validate:
            # Mode validation de qualit√©
            print("üîç Validation de la qualit√© des traductions existantes...")
            analysis_report = translator.analyze_all_files(args.max_files)
            
            # Valider seulement les fichiers traduits
            translated_files = analysis_report.get('translated_files', [])
            
            if not translated_files:
                print("‚ùå Aucun fichier traduit d√©tect√© pour validation")
            else:
                print(f"üìä Validation de {len(translated_files)} fichier(s) traduit(s)...")
                
                total_quality = 0.0
                validated_count = 0
                
                for file_info in translated_files:
                    file_path = Path(file_info['path'])
                    print(f"\nüìÑ Validation: {file_path.name}")
                    
                    validation = translator.validate_integration_quality(file_path)
                    quality = validation['quality_score']
                    
                    print(f"  üìä Score de qualit√©: {quality:.1%}")
                    for rec in validation['recommendations']:
                        print(f"  {rec}")
                    
                    total_quality += quality
                    validated_count += 1
                
                if validated_count > 0:
                    avg_quality = total_quality / validated_count
                    print(f"\nüìà R√âSUM√â DE VALIDATION:")
                    print(f"  üìä Qualit√© moyenne: {avg_quality:.1%}")
                    print(f"  üìÅ Fichiers valid√©s: {validated_count}")
                    
                    if avg_quality >= 0.8:
                        print(f"  üéâ Excellente qualit√© globale !")
                    elif avg_quality >= 0.6:
                        print(f"  ‚úÖ Bonne qualit√© globale")
                    else:
                        print(f"  ‚ö†Ô∏è Qualit√© √† am√©liorer")
                        
        elif args.validate_file:
            # Validation d'un fichier sp√©cifique
            file_path = Path(args.validate_file)
            if file_path.exists():
                print(f"üîç Validation de la qualit√©: {file_path}")
                validation = translator.validate_integration_quality(file_path)
                
                print(f"üìä Score de qualit√©: {validation['quality_score']:.1%}")
                print(f"üìù Textes trouv√©s: {validation['texts_found']}")
                print(f"üîÑ Statut: {validation['translation_status']}")
                
                print(f"\nüí° Recommandations:")
                for rec in validation['recommendations']:
                    print(f"  {rec}")
            else:
                print(f"‚ùå Fichier non trouv√©: {file_path}")
            
        elif args.cache_stats:
            # Affichage des statistiques du cache
            translator = P3FESTranslator(args.game_dir, args.output_dir)
            stats = translator.translation_service.get_cache_stats()
            
            print("üíæ STATISTIQUES DU CACHE DE TRADUCTION")
            print("=" * 40)
            print(f"üìä Taux de hit: {stats['cache_hit_rate']:.1f}%")
            print(f"üè™ Entr√©es totales: {stats['cache_stats']['total_entries']}")
            print(f"üîÑ Hits totaux: {stats['cache_stats']['total_hits']}")
            print(f"üÜï Entr√©es r√©centes (24h): {stats['cache_stats']['recent_entries']}")
            print(f"üìà Traductions demand√©es: {stats['service_stats']['translations_requested']}")
            print(f"‚úÖ Traductions r√©ussies: {stats['service_stats']['successful_translations']}")
            print(f"‚ùå Erreurs de traduction: {stats['service_stats']['translation_errors']}")
            
        elif args.clean_cache:
            # Nettoyage du cache
            translator = P3FESTranslator(args.game_dir, args.output_dir)
            cleaned = translator.translation_service.cleanup_cache()
            print(f"üßπ Cache nettoy√©: {cleaned} entr√©e(s) expir√©e(s) supprim√©e(s)")
            
        elif args.auto or args.auto_test:
            # Mode automatique
            test_mode = args.auto_test
            print(f"ü§ñ Mode automatique {'avec tests' if test_mode else 'standard'}")
            translator.auto_process_directory(test_mode=test_mode, min_score=args.min_score)
            
        elif args.test:
            # Mode test traditionnel
            print("üß™ Mode test - Analyse des fichiers sans traduction...")
            translator.test_mode()
            
        else:
            # Mode traditionnel
            print("üöÄ Mode traditionnel - Traitement des fichiers par extension...")
            translator.process_directory()
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        logging.error(f"Erreur fatale: {e}")
        print(f"‚ùå Erreur fatale: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()